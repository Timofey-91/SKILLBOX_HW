{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cisB24TazhU2"
   },
   "source": [
    "### Урок 11. Домашняя работа\n",
    "\n",
    "**Задание простого уровня** Мы говорили, что метрики качества нужны, чтобы сравнивать различные модели между собой. В задаче полиномиальной регрессии реализуйте код для выбора лучшей степени полиному:\n",
    "\n",
    "* возьмите все степени от 1 до 10 по порядку, без пропусков.\n",
    "* найдите степень полинома, где будет лучший r2-score\n",
    "* напишите код, который выводит самую подходящую степень полинома и соответствующий ей скор\n",
    "\n",
    "Эта процедура называется Grid Search и помогает найти лучшие параметры для модели.\n",
    "\n",
    "Обучите лучшую модель и сделайте predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_train</th>\n",
       "      <th>y_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.138368</td>\n",
       "      <td>0.838812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.157237</td>\n",
       "      <td>0.889313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.188684</td>\n",
       "      <td>1.430040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.685553</td>\n",
       "      <td>1.717309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.874237</td>\n",
       "      <td>2.032588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x_train   y_train\n",
       "0  0.138368  0.838812\n",
       "1  0.157237  0.889313\n",
       "2  0.188684  1.430040\n",
       "3  0.685553  1.717309\n",
       "4  0.874237  2.032588"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data = pd.read_csv('3.10_non_linear.csv', sep=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_degrees(source_data: list, degree: int):\n",
    "    \"\"\"Функция, которая принимает на вход одномерный массив, а возвращает n-мерный\n",
    "    \n",
    "    Для каждой степени от 1 до  degree возводим x в эту степень\n",
    "    \"\"\"\n",
    "    return np.array([\n",
    "          source_data**n for n in range(1, degree + 1)  \n",
    "    ]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def train_polynomial(degree, data):\n",
    "    \"\"\"Генерим данные, тренируем модель\n",
    "    \n",
    "    дополнительно рисуем график\n",
    "    \"\"\"\n",
    "    \n",
    "    X = generate_degrees(data['x_train'], degree)\n",
    "\n",
    "    model = LinearRegression().fit(X, data['y_train'])\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    error =  r2_score(data['y_train'], y_pred)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_polinom(data, max_n):\n",
    "    errors = np.array([train_polynomial(n, data) for n in range(1,max_n+1) ])    \n",
    "    best_degree = np.argmax(errors)+1\n",
    "    return best_degree, errors[best_degree-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подходящая степень полинома 10, ошибка 0.9091133831297264\n"
     ]
    }
   ],
   "source": [
    "result = find_best_polinom(data, 10)\n",
    "print('Подходящая степень полинома %s, ошибка %s' % result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8821009 ,  1.01897615,  1.21593657,  1.90777399,  1.89320072,\n",
       "        1.96799166,  1.99510721,  2.00255721,  2.05113549,  2.05904869,\n",
       "        2.07135523,  2.08488912,  2.08789359,  2.05782452,  1.96152906,\n",
       "        1.7075292 ,  1.25295926,  1.19221977,  1.0369195 ,  1.00291069,\n",
       "        0.88643149,  0.87018977,  0.4841843 ,  0.44549176,  0.29608624,\n",
       "        0.26126528,  0.2025231 ,  0.19922486,  0.17116337,  0.1521614 ,\n",
       "        0.1521614 ,  0.15070412,  0.14577301,  0.13117668,  0.09362254,\n",
       "        0.08594863,  0.07275961,  0.06757112, -0.00888384, -0.00456118,\n",
       "        0.00499669,  0.05865977,  0.10034339,  0.22510017,  0.27123155,\n",
       "        0.37545149,  0.56831659,  0.96442781,  0.93519201,  0.93519201])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = generate_degrees(data['x_train'], 10)\n",
    "\n",
    "model = LinearRegression().fit(X, data.y_train)\n",
    "y_pred = model.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3dSmlAFzhU9"
   },
   "source": [
    "**Задание среднего уровня** Напишите класс для обучения модели, который содержит:\n",
    "\n",
    "* функцию `.fit(X, y)` , которая принимает на вход массив фичей `X`, массив таргетов `y` и обучает коэффициенты регрессии. Код для обучения взять из первого урока модуля *Постановка ML задачи линейной регрессии*\n",
    "* функцию `.predict(X)`, которая по массиву фичей `X` возвращает массив предсказаний `y`\n",
    "\n",
    "Нужно использовать код для аналитически вычисляемых коэффициентов. \n",
    "\n",
    "Это задание позволит понять, как работает линейная регрессия \"внутри\" библиотечной реализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "rayvZFx1zhU9"
   },
   "outputs": [],
   "source": [
    "class CustomLinearReg:\n",
    "    def __init__(self):\n",
    "        self.w = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_new = [1 for i in range(1+len(X)-1)]+X\n",
    "        X_new = np.array(X_new).reshape(-1,2, order='F')\n",
    "        Y_new = np.array(y).reshape(-1,1)\n",
    "        X_T_X = (X_new.T).dot(X_new)\n",
    "        X_T_X_inverted = inv(X_T_X)\n",
    "        self.w = X_T_X_inverted.dot(X_new.T).dot(Y_new)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_new = [1 for i in range(1+len(X)-1)]+X\n",
    "        X_new = np.array(X_new).reshape(-1,2, order='F')\n",
    "        res = X_new.dot(self.w)\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.21428571]\n",
      " [20.35714286]\n",
      " [27.5       ]\n",
      " [48.92857143]]\n"
     ]
    }
   ],
   "source": [
    "x_hw = [50, 60, 70, 100]\n",
    "y_hw = [10, 15, 40, 45]\n",
    "\n",
    "reg= CustomLinearReg().fit(x_hw, y_hw)\n",
    "reg.predict(x_hw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwWP7aPOzhVA"
   },
   "source": [
    "**Задание высокого уровня**\n",
    "\n",
    "1. разделите датасет с домами Бостона из Урока 2 (таргет и фичи) на две части: в одной части 80% датасета (назовём train) в другой 20% (назовём valid) с помощью функции `train_test_split` из библиотеки `sklearn`\n",
    "1. обучите модель только на train датасете\n",
    "1. постройте предсказания valid датасете\n",
    "1. Посчитайте  `r2 score` на валидационном сете\n",
    "\n",
    "После этого примените к обеим датасетам z-преобразование и повторите шаги 2-4. Как изменилась метрика r2?\n",
    "\n",
    "Это задание поможет понять, как валидировать линейную регрессию (и другие модели) на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "f6p8B0VB5mHa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score до z-преобразования -0.252942, после 0.062840\n"
     ]
    }
   ],
   "source": [
    "boston_dataset = load_boston()\n",
    "\n",
    "features_train = boston_dataset.data[:round(boston_dataset.data.shape[0]*0.8),:]\n",
    "features_valid = boston_dataset.data[round(boston_dataset.data.shape[0]*0.8):,:]\n",
    "\n",
    "y_train = boston_dataset.target[:round(boston_dataset.target.shape[0]*0.8)]\n",
    "y_valid = boston_dataset.target[round(boston_dataset.target.shape[0]*0.8):]\n",
    "\n",
    "reg = LinearRegression().fit(features_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(features_valid)\n",
    "\n",
    "error_before = r2_score(y_valid, y_pred)\n",
    "\n",
    "\n",
    "y_train = StandardScaler().fit_transform(y_train.reshape(-1,1)).reshape(-1) \n",
    "y_valid = StandardScaler().fit_transform(y_valid.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "reg = LinearRegression().fit(features_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(features_valid)\n",
    "\n",
    "error_after = r2_score(y_valid, y_pred)\n",
    "error_after\n",
    "\n",
    "print('r2 score до z-преобразования %f, после %f' %(error_before, error_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод:\n",
    "Из данных приведеных выше, после z-преоброзования r2 score стал больше, значит ошибка уменьшилась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "jun_ml_linear_regression_I-hw_11.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
