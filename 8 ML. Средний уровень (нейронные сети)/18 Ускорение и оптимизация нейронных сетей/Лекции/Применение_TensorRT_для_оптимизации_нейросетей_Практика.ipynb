{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Применение TensorRT для оптимизации нейросетей. Практика.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgshItiNbYmH"
      },
      "source": [
        "# Применение TensorRT для оптимизации нейросетей\n",
        "\n",
        "В этом уроке мы рассмотрим на практике оптимизацию и инференс нейронной сети с помощью библотеки TensorRT.\n",
        "\n",
        "Изначально TensorRT существовала в виде отдельной бибилотеки, но относительно недавно её функционал был в том числе интегрирован в TensorFlow. Именно этим мы и воспользуемся в этом уроке. При такой интеграции на выходе мы всё еще получаем TensorFlow модель, просто часть её графа будут оптимизированы и вычислены (во время инференса) с помощью TensorRT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yeG_jLT-b2h"
      },
      "source": [
        "### Используем TensorFlow 2.0\n",
        "\n",
        "На момент подготовки этих материалов в Google Colab по умолчанию используется версия TensorFlow 1.X\n",
        "\n",
        "Переключаемся на версию 2.0 (работает только в Colab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mpXpfED-Z7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e286d7cf-fc2c-4576-b78f-1464738b57de"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1c9g1MHeUCl"
      },
      "source": [
        "### Загрузка библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPJ0YaW58SXY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1DhfdwVUYlr"
      },
      "source": [
        "### Импорт TensorRT\n",
        " Будем использовать TensorRT, котрый идёт внутри TensorFlow.\n",
        "\n",
        " В реальной среде может потребоваться произвести дополнительную установку недостающих компонентов TensorRT, но в Google Colab уже установлено всё, что нужно.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgvRbJrJsxHs"
      },
      "source": [
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpMn7JDZUk9l"
      },
      "source": [
        "### Создание модели \n",
        "\n",
        "Создадим свёрточную нейронную сеть с большим количеством свёрточных слоёв.\n",
        "\n",
        "Кроме того, для TensorRT оптимизации необходимо фиксировать размер входа. Делаем это с помощью метода `_set_inputs()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KJfXErosxF7"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "     tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.MaxPool2D((2, 2)),\n",
        "     tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.MaxPool2D((2, 2)),\n",
        "     tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.MaxPool2D((2, 2)),\n",
        "     tf.keras.layers.Flatten(),\n",
        "     tf.keras.layers.Dense(128, activation='relu'),\n",
        "     tf.keras.layers.Dense(128, activation='relu'),\n",
        "     tf.keras.layers.Dense(128, activation='relu'),\n",
        "     tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model._set_inputs(np.zeros((1, 28, 28, 1), dtype=np.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLuDFOgBUpHj"
      },
      "source": [
        "### Сохранение модели \n",
        "\n",
        "Сохраним модель в виде `saved_model`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAGeUP93sxCO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "f2f10ce7-6d72-4df7-db17-dc3ef358f3dc"
      },
      "source": [
        "model.save('saved_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6run0z2UrgO"
      },
      "source": [
        "### Оптимизация модели с помощью TensorFlow\n",
        "\n",
        "А теперь давайте произведем оптимизацию нашей модели с помощью TensorRT.\n",
        "\n",
        "Сначала создадим TensorRT конвертер (`converter`) и укажем ему путь до нашей сохранённой неоптимизированной TensorFlow модели. Если нужно как-то еще сконфигурировать процесс оптимизации, можно передать дополнительные параметры в конструктор `TrtGraphConverterV2`, но мы будем использовать параметры по умолчанию.\n",
        "\n",
        "После этого просто вызываем метод `convert()` и TensorRT применит все свои стратегии для оптимизации нашей модели. Важно запускать этот ноутбук в режиме GPU, так как TensorRT работает только с GPU.\n",
        "\n",
        "После оптимизации можно сохранить новую модель в стандартном формате `saved_model`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IefTmdcqsxAN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "74257b8d-c5ab-4ad9-c7c1-f3d6c6f2e208"
      },
      "source": [
        "converter = trt.TrtGraphConverterV2(input_saved_model_dir='saved_model')\n",
        "converter.convert()\n",
        "converter.save('saved_model_trt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Linked TensorRT version: (0, 0, 0)\n",
            "INFO:tensorflow:Loaded TensorRT version: (0, 0, 0)\n",
            "INFO:tensorflow:Assets written to: saved_model_trt/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvVLetldUwBD"
      },
      "source": [
        "### Загрузка оптимизированной TensorRT модели\n",
        "\n",
        "Теперь можно загрузить оптимизированную модель и произвести инференс. Во время инференса такой модели TensorFlow будет обращаться к инференс движку TensorRT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhTS4MvUsw-h"
      },
      "source": [
        "model_trt = tf.keras.models.load_model('saved_model_trt')\n",
        "\n",
        "# Warm-up\n",
        "_=model_trt(np.zeros((1, 28, 28, 1), dtype=np.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8HybVM0UDHj"
      },
      "source": [
        "### Сравнение скорости работы двух моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKgvp222UHev"
      },
      "source": [
        "Запустим инференс для обеих моделей со случайным входом и узнаем среднюю скорость работы каждой из моделей с помощью магической команды `%%timeit`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqP7bYrrtO_5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4db5d65-5338-483d-bc98-fc39a4d4987e"
      },
      "source": [
        "%%timeit -n 10 -r 10\n",
        "\n",
        "q = model(np.zeros((1, 28, 28, 1), dtype=np.float32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 10: 5.58 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv97jcIjtPBl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1f309cc8-238f-47eb-e6d2-6570d95b90b4"
      },
      "source": [
        "%%timeit -n 10 -r 10\n",
        "\n",
        "q = model_trt(np.zeros((1, 28, 28, 1), dtype=np.float32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 10: 1.07 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xdcUkufULqX"
      },
      "source": [
        "TensorRT модель получилась быстрее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcyTQv6euJnx"
      },
      "source": [
        "**[Задание 1]** Сравните скорость работы двух моделей при различных гиперпараметрах (размер батча, размер входа, количество слоёв). Рассчитайте коэффициент ускорения (во сколько раз одна модель быстрее другой) для каждой конфигурации. Постройте соответствующие графики. (Например, график зависимости ускорения от размера входа при условии, что всё остальное фиксировано). Для этого задания вам понадобится самостоятельно реализовать способ измерения среднего времени инференса модели."
      ]
    }
  ]
}