{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b440sCmKapRt"
   },
   "source": [
    "# Домашняя работа\n",
    "\n",
    "## Урок 2. \n",
    "\n",
    "### Задание начального уровня\n",
    "\n",
    "\n",
    "Примените процедуру токенизации к файлу `brand_tweets_valid.csv`\n",
    "\n",
    "Сколько *уникальных* токенов получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qzrWClC1apR4"
   },
   "outputs": [],
   "source": [
    "# стоп-слова\n",
    "stop_words = [\n",
    "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\",\n",
    "    'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers',\n",
    "    'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',\n",
    "    'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been',\n",
    "    'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if',\n",
    "    'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between',\n",
    "    'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out',\n",
    "    'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why',\n",
    "    'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not',\n",
    "    'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'shold',\n",
    "    \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\",\n",
    "    'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\",\n",
    "    'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\",\n",
    "    'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5FBTDc5xapSO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to ....\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Wow! Google maps for mobile v5 demo at #sxsw. Very nice.',\n",
       "       'The #google name was built on gettinng stuff out there and trying it with users to see what works. #marissagoogle #sxsw',\n",
       "       '&quot;Apple opening a temporary store in Austin for SXSW and the iPad 2 launch:&quot; {link} #SXSW',\n",
       "       '#tech Apple Opening Pop-Up Store In Austin For #SXSW {link}',\n",
       "       'GSDM Google party is off the hook! #SXSW  {link}'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "nltk.download('punkt', download_dir='.')\n",
    "df = pd.read_csv(\"brand_tweets_valid.csv\")\n",
    "tweets = df[\"tweet_text\"].values\n",
    "\n",
    "tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных токенов: 2097\n"
     ]
    }
   ],
   "source": [
    "#Количество уникальных токенов\n",
    "X = [nltk.tokenize.word_tokenize(t) for t in tweets]\n",
    "X_ = [[t for t in tweet if t not in stop_words] for tweet in X]\n",
    "\n",
    "unique = set()\n",
    "for tweet in X_:\n",
    "    for t in tweet:\n",
    "       unique.add(t)\n",
    "\n",
    "print('Количество уникальных токенов:',len(unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Урок 3 \n",
    "\n",
    "### Задание начального уровня\n",
    "\n",
    "Потренируйтесь в нахождении матрицы схожести для валидационного сета\n",
    "\n",
    "* загрузите `brand_tweets_valid.csv`\n",
    "* примените объект `vectorizer`, обученный на датасете `brand_tweets.csv` (просто скопируйте этот код из урока)\n",
    "* примените функцию `pairwise_distances` к полученной матрице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<402x1900 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8753 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "df_valid = pd.read_csv('brand_tweets_valid.csv', sep=',', encoding='utf8')\n",
    "# удаляем строки, в которых отсутствует текст твита\n",
    "df_valid.drop(df[df.tweet_text.isnull()].index, inplace=True)\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "vectorizer = CountVectorizer(tokenizer=nltk.tokenize.word_tokenize)\n",
    "\n",
    "document_matrix = vectorizer.fit_transform(df.tweet_text.values)\n",
    "document_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402, 402)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "tweet_distance = 1-pairwise_distances(document_matrix, metric=\"cosine\")\n",
    "\n",
    "tweet_distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание среднего уровня\n",
    "\n",
    "Пользуясь матрицей схожести, полученной на предыдущем этапе, найдите top-5 твитов, похожих на твит валидационного сета с `id=14`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popup Apple Store crew has been giving out water to the people in line but they are in street clothes. No Apple logos anywhere yet. #SXSW\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "249    just got mine &amp; i disagree RT  @mention Pe...\n",
       "244    marcelosomers: New version of Google Maps for ...\n",
       "94     Google will preview major new social service, ...\n",
       "220    Yay! RT @mention Hoot! New Blog post: HootSuit...\n",
       "184    Google's Marissa Meyers: &quot;Some of our pro...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweet_index = 14\n",
    "\n",
    "print(df_valid.iloc[test_tweet_index].tweet_text+'\\n------------------------------\\n')\n",
    "\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "t_d = np.argsort(tweet_distance[test_tweet_index, :])\n",
    "\n",
    "df_valid.iloc[t_d[1:6]].tweet_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание высокого уровня.\n",
    "\n",
    "У вас есть матрица схожести между объектами. Попробуйте решить задачу поиска дубликатов в тексте\n",
    "\n",
    "1. Визуализируйте гистограмму значений в матрице схожести.\n",
    "1. Напишите функцию на Python, которая принимает индекс твита, пороговое значение (число от $0.0$ до $1.0$ и матрицу схожести, а затем выводит все твиты, схожесть которых больше, чем пороговое значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "x,y = np.histogram(tweet_distance)\n",
    "plt.hist(y[:-1], y, weights=x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popup Apple Store crew has been giving out water to the people in line but they are in street clothes. No Apple logos anywhere yet. #SXSW\n",
      "------------------------------\n",
      "[ 14 132]\n",
      "More similar than  0.5 :\n",
      "Tweet # 132 :  Apple employees just showed up in force to the #SXSW PopUp Apple Store. #iPad2\n"
     ]
    }
   ],
   "source": [
    "def more_similar(tweet_index, threshold, t_d):\n",
    "    print(df_valid.iloc[tweet_index].tweet_text+'\\n------------------------------')\n",
    "    a = t_d[tweet_index, :].squeeze()\n",
    "    indices = np.argwhere(a > threshold).squeeze()\n",
    "    print(indices)\n",
    "    print(\"More similar than \", threshold, \":\")\n",
    "    for i in indices:\n",
    "        if i == tweet_index: continue\n",
    "        print(\"Tweet #\", i, \": \", df_valid.iloc[i].tweet_text)\n",
    "\n",
    "more_similar(14, 0.5, tweet_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Урок 4.\n",
    "\n",
    "### Задание начального уровня\n",
    "\n",
    "Обучите модель Skip-Gram (передав параметр `sg=1`. Какие top-10 слов больше всего похожи на слово `iphone` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv('brand_tweets_valid.csv', sep=',', encoding='utf8')\n",
    "# удаляем строки, в которых отсутствует текст твита\n",
    "df_valid.drop(df[df.tweet_text.isnull()].index, inplace=True)\n",
    "df_valid[\"tokenized\"] = df_valid[\"tweet_text\"].apply(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "2021-08-19 18:50:19,285 : INFO : collecting all words and their counts\n",
      "2021-08-19 18:50:19,287 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-08-19 18:50:19,299 : INFO : collected 2202 word types from a corpus of 9827 raw words and 402 sentences\n",
      "2021-08-19 18:50:19,302 : INFO : Creating a fresh vocabulary\n",
      "2021-08-19 18:50:19,331 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 739 unique words (33.560399636693916%% of original 2202, drops 1463)', 'datetime': '2021-08-19T18:50:19.330988', 'gensim': '4.0.1', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-08-19 18:50:19,340 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 8364 word corpus (85.11244530375497%% of original 9827, drops 1463)', 'datetime': '2021-08-19T18:50:19.340984', 'gensim': '4.0.1', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-08-19 18:50:19,396 : INFO : deleting the raw counts dictionary of 2202 items\n",
      "2021-08-19 18:50:19,400 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2021-08-19 18:50:19,404 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4798.626774852113 word corpus (57.4%% of prior 8364)', 'datetime': '2021-08-19T18:50:19.403987', 'gensim': '4.0.1', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-08-19 18:50:19,481 : INFO : estimated required memory for 739 words and 10 dimensions: 428620 bytes\n",
      "2021-08-19 18:50:19,483 : INFO : resetting layer weights\n",
      "2021-08-19 18:50:19,487 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-08-19T18:50:19.487993', 'gensim': '4.0.1', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-08-19 18:50:19,490 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 739 vocabulary and 10 features, using sg=1 hs=0 sample=0.001 negative=5 window=7', 'datetime': '2021-08-19T18:50:19.490981', 'gensim': '4.0.1', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-08-19 18:50:19,515 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-08-19 18:50:19,538 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-19 18:50:19,544 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-19 18:50:19,629 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-19 18:50:19,632 : INFO : EPOCH - 1 : training on 9827 raw words (4735 effective words) took 0.1s, 37291 effective words/s\n",
      "2021-08-19 18:50:19,656 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-08-19 18:50:19,662 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-19 18:50:19,665 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-19 18:50:19,752 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-19 18:50:19,756 : INFO : EPOCH - 2 : training on 9827 raw words (4780 effective words) took 0.1s, 43341 effective words/s\n",
      "2021-08-19 18:50:19,780 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-08-19 18:50:19,787 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-19 18:50:19,796 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-19 18:50:19,899 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-19 18:50:19,902 : INFO : EPOCH - 3 : training on 9827 raw words (4759 effective words) took 0.1s, 36386 effective words/s\n",
      "2021-08-19 18:50:19,923 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-08-19 18:50:19,929 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-19 18:50:19,933 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-19 18:50:20,041 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-19 18:50:20,045 : INFO : EPOCH - 4 : training on 9827 raw words (4831 effective words) took 0.1s, 39578 effective words/s\n",
      "2021-08-19 18:50:20,081 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-08-19 18:50:20,087 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-19 18:50:20,091 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-19 18:50:20,200 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-19 18:50:20,207 : INFO : EPOCH - 5 : training on 9827 raw words (4824 effective words) took 0.1s, 34251 effective words/s\n",
      "2021-08-19 18:50:20,241 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-08-19 18:50:20,246 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-19 18:50:20,257 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-19 18:50:20,369 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-19 18:50:20,371 : INFO : EPOCH - 6 : training on 9827 raw words (4767 effective words) took 0.1s, 33955 effective words/s\n",
      "2021-08-19 18:50:20,394 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-08-19 18:50:20,397 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-19 18:50:20,401 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-19 18:50:20,511 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-19 18:50:20,518 : INFO : EPOCH - 7 : training on 9827 raw words (4762 effective words) took 0.1s, 36097 effective words/s\n",
      "2021-08-19 18:50:20,549 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-08-19 18:50:20,551 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-19 18:50:20,556 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-19 18:50:20,683 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-19 18:50:20,687 : INFO : EPOCH - 8 : training on 9827 raw words (4760 effective words) took 0.1s, 31860 effective words/s\n",
      "2021-08-19 18:50:20,711 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-08-19 18:50:20,715 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-19 18:50:20,723 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-19 18:50:20,815 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-19 18:50:20,819 : INFO : EPOCH - 9 : training on 9827 raw words (4847 effective words) took 0.1s, 40770 effective words/s\n",
      "2021-08-19 18:50:20,843 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-08-19 18:50:20,847 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-08-19 18:50:20,851 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-08-19 18:50:20,941 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-08-19 18:50:20,946 : INFO : EPOCH - 10 : training on 9827 raw words (4776 effective words) took 0.1s, 42095 effective words/s\n",
      "2021-08-19 18:50:20,954 : INFO : Word2Vec lifecycle event {'msg': 'training on 98270 raw words (47841 effective words) took 1.5s, 32728 effective words/s', 'datetime': '2021-08-19T18:50:20.954987', 'gensim': '4.0.1', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-08-19 18:50:20,962 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=739, vector_size=10, alpha=0.025)', 'datetime': '2021-08-19T18:50:20.962986', 'gensim': '4.0.1', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "texts = df_valid.tokenized.values\n",
    "\n",
    "model = Word2Vec(texts, vector_size=10, window=7, min_count=2, workers=4, epochs=10, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Atrix', 0.9931920170783997),\n",
       " ('does', 0.990644633769989),\n",
       " ('experience', 0.9904371500015259),\n",
       " ('seem', 0.9898284077644348),\n",
       " ('Managed', 0.9897992014884949),\n",
       " ('amazing', 0.9886273741722107),\n",
       " ('cool', 0.98694908618927),\n",
       " ('few', 0.9857677817344666),\n",
       " ('IPad', 0.9856570959091187),\n",
       " ('Ready', 0.9856477379798889)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('iphone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mid_ml_nlp_hw-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
