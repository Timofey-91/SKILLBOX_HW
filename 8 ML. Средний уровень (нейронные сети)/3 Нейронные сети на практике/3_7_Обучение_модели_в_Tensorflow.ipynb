{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.7 Обучение модели в Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kuM0Ad00gEi"
      },
      "source": [
        "# Обучение модели в Tensorflow\n",
        "\n",
        "На прошлом уроке мы узнали, как описывать модель. Теперь мы должны понять как определять две другие важные составляющие пайплайна -- лосс функцию и оптимизатор. И наконец, понять как это все соединить вместе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w7jiv8kP7gM"
      },
      "source": [
        "##Определение лосс функции\n",
        "\n",
        "На протяжении курса вы познакомились как минимум с тремя типами функций потерь \n",
        "\n",
        "\n",
        "*   MSE (mean squared error) -- для задачи регрессии\n",
        "*   Binary cross entropy -- для задачи бинарной классификации\n",
        "*   Categorical cross entropy -- для задачи многоклассовой классификации\n",
        "\n",
        "Все они реализованы в Keras и находятся в tf.keras.losses:\n",
        "*   tf.keras.losses.MSE()\n",
        "*   tf.keras.losses.binary_crossentropy()\n",
        "*   tf.keras.losses.sparse_categorical_crossentropy()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3jXmnKqR0N9"
      },
      "source": [
        "import tensorflow as tf\n",
        "#tf.enable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keC_WKagSTfB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b2f0fda-a9b8-447e-c4d7-ce44b0960866"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "y_true = np.random.rand(10)\n",
        "y_pred = np.random.rand(10)\n",
        "\n",
        "# лосс функция принимает предсказанные значение и реальные, и возвращает значение -- все просто\n",
        "print(tf.keras.losses.MSE(y_true=y_true, y_pred=y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.21203114813561502, shape=(), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWBW7YEVtrLW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "56698e85-729e-4873-f371-a043fc56d191"
      },
      "source": [
        "# Можно проверить, правильно ли она реализована в Keras :)\n",
        "print(np.mean((y_true - y_pred)**2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.30679543373769713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3Qci-dpuQTP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b0e7a578-4e06-43cf-acc4-ebb07421c3da"
      },
      "source": [
        "print(tf.keras.losses.binary_crossentropy(np.ones(10), np.ones(10)))\n",
        "\n",
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "print(loss(np.ones(10), np.ones(10)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.0, shape=(), dtype=float64)\n",
            "tf.Tensor(0.0, shape=(), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1K29G5sUdfM"
      },
      "source": [
        "Но у некоторых функций есть особенности -- например у sparse_categorical_crossentropy. Взгляните на ее сигнатуру ниже:\n",
        "\n",
        "*Если в Colab написать знак вопроса после функции, можно получить ее сигнатуру и описание входных переменных*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_wEdJ1IUbmn"
      },
      "source": [
        "tf.keras.losses.SparseCategoricalCrossentropy?\n",
        "\n",
        "# обратите внимание на from_logits=False, аналогично в tf.keras.losses.BinaryCrossentropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voKfQFwMVCEG"
      },
      "source": [
        "Обратите внимание, что она принимает дополнительный параметр -- from_logits. Здесь стоит напомнить, что данную лосс функцию можно считать двумя способами -- из предсказанных вероятностей и из предсказанных логитов. *Мы использовали этот трюк в последнем домашнем задании*. \n",
        "\n",
        "Напомню, что сеть изначально предсказывает логиты, и затем мы превращаем их в вероятности --  с помощью функции активации. Но т.к. мы знаем, что нам предстоит считать лосс, то мы можем не тратить \"силы\" на вычисление вероятностей и посчитать лосс основываясь на логитах (логарифм + экспонента сильно упрощают запись). Мы как бы перебросили активацию из слоя в лосс и оставили “голый” слой без активации. Такая запись проще и вычислительно более стабильная.\n",
        "\n",
        "\n",
        "**Важно помнить, что в случае использования логитов (from_logits=True), последний слой должен быть без активации. Это очень распространенная ошибка. Всегда помните об этом.**\n",
        "\n",
        "Ниже приведем небольшую шпаргалку о том, как комбинировать активацию последнего слоя с лосс функцией:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKTYJx1H0Bjn"
      },
      "source": [
        "*Для задачи классификации*\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1meej-OaIyY4ix00j1zHtBQbkRpwwlA2f)\n",
        "![alt text](https://drive.google.com/uc?export=view&id=15XvkHAUN6z23RI1UgtBJe94sQ1KNlqiq)\n",
        "*Для задачи регрессии*\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1gGkI7RO_tdyaMr8I77ia5BTkJ1kqzo7F)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9H8nw02WwR5"
      },
      "source": [
        "## Определение оптимизатора\n",
        "\n",
        "С оптимизатором -- все аналогично. Они живут в tf.keras.optimizers. Например:\n",
        "*  tf.keras.optimizers.Adam\n",
        "*  tf.keras.optimizers.SGD и многие другие.\n",
        "\n",
        "Каждый из оптимизаторов имеет свои параметры, но все разделяют общий -- learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPrrLKMEXGAS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5e9d05ce-924f-4108-b3f1-b4b5694d57a9"
      },
      "source": [
        "tf.keras.optimizers.Adam, tf.keras.optimizers.SGD()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensorflow.python.keras.optimizer_v2.adam.Adam,\n",
              " <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD at 0x7f786a38f160>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpSOIHLeDRk3"
      },
      "source": [
        "# Собираем все вместе"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md5HvWF1ZaDg"
      },
      "source": [
        "##Задача регрессии\n",
        "\n",
        "Рассмотрим простую задачу определения коэффициентов зависимости шкалы фаренгейта от цельсия. Это классическая формулировка задачи линейной регрессии. Известно, что эта зависимость линейная -- давайте посчитаем ее параметры, исходя из данных:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI9GVZ8hePYG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5ceb11e5-1418-4675-c02c-938470c07066"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.enable_eager_execution()\n",
        "print(tf.__version__)\n",
        "\n",
        "# определим наш скромный датасет\n",
        "celsius = np.array([-10, -40, 10, 20, 36, 5, -12, 14, 36]).astype(np.float32)\n",
        "fahrenheit = np.array([14., -40., 50., 68., 96.8, 41., 10.4, 57.2, 96.8])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mL-sD-a7nqq"
      },
      "source": [
        "model = tf.keras.Sequential() # модель состоит из одного слоя с одним выходом и входом.\n",
        "model.add(tf.keras.layers.Dense(1, input_shape=(1,)))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.5) \n",
        "loss = tf.keras.losses.MSE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npUkFJECUaiu"
      },
      "source": [
        "# cледующий шаг -- компиляция модели: \"связываем\" модель, оптимайзер и лосс\n",
        "model.compile(optimizer=optimizer, loss=loss) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbp6B-bB5aWG"
      },
      "source": [
        "# и наконец, обучение модели с помощью метода model.fit.\n",
        "\n",
        "model.fit?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8Y2pZX26HWL"
      },
      "source": [
        " Сигнатура выглядит следующим образом (часть параметров, которые мы не будем использовать в ближайшее время скрыта).\n",
        "\n",
        "```\n",
        "model.fit(x=None, y=None, batch_size=None, epochs=1, validation_data=None, shuffle=True, ...)\n",
        "```\n",
        "\n",
        "*   x, y -- обучающая выборка, входные признаки и ответы\n",
        "*   batch_size -- размер батча при обучении\n",
        "*   epochs -- количество эпох\n",
        "*   validation_data -- данные для валидации, например, (x_val, y_val)\n",
        "*   shuffle -- перемешивать данные при обучении или нет\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V2WZp6F5yCG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ab75769-e424-40ba-e635-4d5a8dddc2c6"
      },
      "source": [
        "history = model.fit(celsius, fahrenheit, epochs=200, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 - 0s - loss: 3713.9521\n",
            "Epoch 2/200\n",
            "9/9 - 0s - loss: 2557.6189\n",
            "Epoch 3/200\n",
            "9/9 - 0s - loss: 1705.2397\n",
            "Epoch 4/200\n",
            "9/9 - 0s - loss: 1151.2064\n",
            "Epoch 5/200\n",
            "9/9 - 0s - loss: 872.1020\n",
            "Epoch 6/200\n",
            "9/9 - 0s - loss: 818.5604\n",
            "Epoch 7/200\n",
            "9/9 - 0s - loss: 913.2064\n",
            "Epoch 8/200\n",
            "9/9 - 0s - loss: 1063.7827\n",
            "Epoch 9/200\n",
            "9/9 - 0s - loss: 1189.8436\n",
            "Epoch 10/200\n",
            "9/9 - 0s - loss: 1244.6080\n",
            "Epoch 11/200\n",
            "9/9 - 0s - loss: 1217.7980\n",
            "Epoch 12/200\n",
            "9/9 - 0s - loss: 1124.5447\n",
            "Epoch 13/200\n",
            "9/9 - 0s - loss: 991.9607\n",
            "Epoch 14/200\n",
            "9/9 - 0s - loss: 849.1221\n",
            "Epoch 15/200\n",
            "9/9 - 0s - loss: 720.8692\n",
            "Epoch 16/200\n",
            "9/9 - 0s - loss: 624.2834\n",
            "Epoch 17/200\n",
            "9/9 - 0s - loss: 567.0149\n",
            "Epoch 18/200\n",
            "9/9 - 0s - loss: 547.2227\n",
            "Epoch 19/200\n",
            "9/9 - 0s - loss: 555.2091\n",
            "Epoch 20/200\n",
            "9/9 - 0s - loss: 576.6293\n",
            "Epoch 21/200\n",
            "9/9 - 0s - loss: 596.5931\n",
            "Epoch 22/200\n",
            "9/9 - 0s - loss: 603.4728\n",
            "Epoch 23/200\n",
            "9/9 - 0s - loss: 591.2872\n",
            "Epoch 24/200\n",
            "9/9 - 0s - loss: 560.1675\n",
            "Epoch 25/200\n",
            "9/9 - 0s - loss: 515.1695\n",
            "Epoch 26/200\n",
            "9/9 - 0s - loss: 464.1252\n",
            "Epoch 27/200\n",
            "9/9 - 0s - loss: 415.2688\n",
            "Epoch 28/200\n",
            "9/9 - 0s - loss: 375.1910\n",
            "Epoch 29/200\n",
            "9/9 - 0s - loss: 347.4871\n",
            "Epoch 30/200\n",
            "9/9 - 0s - loss: 332.2878\n",
            "Epoch 31/200\n",
            "9/9 - 0s - loss: 326.6933\n",
            "Epoch 32/200\n",
            "9/9 - 0s - loss: 325.9342\n",
            "Epoch 33/200\n",
            "9/9 - 0s - loss: 324.8972\n",
            "Epoch 34/200\n",
            "9/9 - 0s - loss: 319.5537\n",
            "Epoch 35/200\n",
            "9/9 - 0s - loss: 307.8909\n",
            "Epoch 36/200\n",
            "9/9 - 0s - loss: 290.1429\n",
            "Epoch 37/200\n",
            "9/9 - 0s - loss: 268.3637\n",
            "Epoch 38/200\n",
            "9/9 - 0s - loss: 245.5638\n",
            "Epoch 39/200\n",
            "9/9 - 0s - loss: 224.7186\n",
            "Epoch 40/200\n",
            "9/9 - 0s - loss: 207.9330\n",
            "Epoch 41/200\n",
            "9/9 - 0s - loss: 195.9680\n",
            "Epoch 42/200\n",
            "9/9 - 0s - loss: 188.2135\n",
            "Epoch 43/200\n",
            "9/9 - 0s - loss: 183.0624\n",
            "Epoch 44/200\n",
            "9/9 - 0s - loss: 178.5303\n",
            "Epoch 45/200\n",
            "9/9 - 0s - loss: 172.9040\n",
            "Epoch 46/200\n",
            "9/9 - 0s - loss: 165.2170\n",
            "Epoch 47/200\n",
            "9/9 - 0s - loss: 155.4262\n",
            "Epoch 48/200\n",
            "9/9 - 0s - loss: 144.2769\n",
            "Epoch 49/200\n",
            "9/9 - 0s - loss: 132.9424\n",
            "Epoch 50/200\n",
            "9/9 - 0s - loss: 122.5850\n",
            "Epoch 51/200\n",
            "9/9 - 0s - loss: 113.9838\n",
            "Epoch 52/200\n",
            "9/9 - 0s - loss: 107.3410\n",
            "Epoch 53/200\n",
            "9/9 - 0s - loss: 102.3003\n",
            "Epoch 54/200\n",
            "9/9 - 0s - loss: 98.1452\n",
            "Epoch 55/200\n",
            "9/9 - 0s - loss: 94.0878\n",
            "Epoch 56/200\n",
            "9/9 - 0s - loss: 89.5381\n",
            "Epoch 57/200\n",
            "9/9 - 0s - loss: 84.2672\n",
            "Epoch 58/200\n",
            "9/9 - 0s - loss: 78.4239\n",
            "Epoch 59/200\n",
            "9/9 - 0s - loss: 72.4198\n",
            "Epoch 60/200\n",
            "9/9 - 0s - loss: 66.7421\n",
            "Epoch 61/200\n",
            "9/9 - 0s - loss: 61.7692\n",
            "Epoch 62/200\n",
            "9/9 - 0s - loss: 57.6518\n",
            "Epoch 63/200\n",
            "9/9 - 0s - loss: 54.2929\n",
            "Epoch 64/200\n",
            "9/9 - 0s - loss: 51.4183\n",
            "Epoch 65/200\n",
            "9/9 - 0s - loss: 48.7002\n",
            "Epoch 66/200\n",
            "9/9 - 0s - loss: 45.8807\n",
            "Epoch 67/200\n",
            "9/9 - 0s - loss: 42.8517\n",
            "Epoch 68/200\n",
            "9/9 - 0s - loss: 39.6670\n",
            "Epoch 69/200\n",
            "9/9 - 0s - loss: 36.4931\n",
            "Epoch 70/200\n",
            "9/9 - 0s - loss: 33.5257\n",
            "Epoch 71/200\n",
            "9/9 - 0s - loss: 30.9089\n",
            "Epoch 72/200\n",
            "9/9 - 0s - loss: 28.6861\n",
            "Epoch 73/200\n",
            "9/9 - 0s - loss: 26.7974\n",
            "Epoch 74/200\n",
            "9/9 - 0s - loss: 25.1167\n",
            "Epoch 75/200\n",
            "9/9 - 0s - loss: 23.5086\n",
            "Epoch 76/200\n",
            "9/9 - 0s - loss: 21.8800\n",
            "Epoch 77/200\n",
            "9/9 - 0s - loss: 20.2070\n",
            "Epoch 78/200\n",
            "9/9 - 0s - loss: 18.5308\n",
            "Epoch 79/200\n",
            "9/9 - 0s - loss: 16.9279\n",
            "Epoch 80/200\n",
            "9/9 - 0s - loss: 15.4717\n",
            "Epoch 81/200\n",
            "9/9 - 0s - loss: 14.2013\n",
            "Epoch 82/200\n",
            "9/9 - 0s - loss: 13.1096\n",
            "Epoch 83/200\n",
            "9/9 - 0s - loss: 12.1515\n",
            "Epoch 84/200\n",
            "9/9 - 0s - loss: 11.2671\n",
            "Epoch 85/200\n",
            "9/9 - 0s - loss: 10.4068\n",
            "Epoch 86/200\n",
            "9/9 - 0s - loss: 9.5482\n",
            "Epoch 87/200\n",
            "9/9 - 0s - loss: 8.6995\n",
            "Epoch 88/200\n",
            "9/9 - 0s - loss: 7.8888\n",
            "Epoch 89/200\n",
            "9/9 - 0s - loss: 7.1478\n",
            "Epoch 90/200\n",
            "9/9 - 0s - loss: 6.4958\n",
            "Epoch 91/200\n",
            "9/9 - 0s - loss: 5.9325\n",
            "Epoch 92/200\n",
            "9/9 - 0s - loss: 5.4397\n",
            "Epoch 93/200\n",
            "9/9 - 0s - loss: 4.9911\n",
            "Epoch 94/200\n",
            "9/9 - 0s - loss: 4.5637\n",
            "Epoch 95/200\n",
            "9/9 - 0s - loss: 4.1461\n",
            "Epoch 96/200\n",
            "9/9 - 0s - loss: 3.7404\n",
            "Epoch 97/200\n",
            "9/9 - 0s - loss: 3.3577\n",
            "Epoch 98/200\n",
            "9/9 - 0s - loss: 3.0108\n",
            "Epoch 99/200\n",
            "9/9 - 0s - loss: 2.7073\n",
            "Epoch 100/200\n",
            "9/9 - 0s - loss: 2.4459\n",
            "Epoch 101/200\n",
            "9/9 - 0s - loss: 2.2178\n",
            "Epoch 102/200\n",
            "9/9 - 0s - loss: 2.0112\n",
            "Epoch 103/200\n",
            "9/9 - 0s - loss: 1.8161\n",
            "Epoch 104/200\n",
            "9/9 - 0s - loss: 1.6280\n",
            "Epoch 105/200\n",
            "9/9 - 0s - loss: 1.4486\n",
            "Epoch 106/200\n",
            "9/9 - 0s - loss: 1.2827\n",
            "Epoch 107/200\n",
            "9/9 - 0s - loss: 1.1352\n",
            "Epoch 108/200\n",
            "9/9 - 0s - loss: 1.0083\n",
            "Epoch 109/200\n",
            "9/9 - 0s - loss: 0.9002\n",
            "Epoch 110/200\n",
            "9/9 - 0s - loss: 0.8060\n",
            "Epoch 111/200\n",
            "9/9 - 0s - loss: 0.7205\n",
            "Epoch 112/200\n",
            "9/9 - 0s - loss: 0.6399\n",
            "Epoch 113/200\n",
            "9/9 - 0s - loss: 0.5632\n",
            "Epoch 114/200\n",
            "9/9 - 0s - loss: 0.4915\n",
            "Epoch 115/200\n",
            "9/9 - 0s - loss: 0.4271\n",
            "Epoch 116/200\n",
            "9/9 - 0s - loss: 0.3717\n",
            "Epoch 117/200\n",
            "9/9 - 0s - loss: 0.3253\n",
            "Epoch 118/200\n",
            "9/9 - 0s - loss: 0.2862\n",
            "Epoch 119/200\n",
            "9/9 - 0s - loss: 0.2522\n",
            "Epoch 120/200\n",
            "9/9 - 0s - loss: 0.2210\n",
            "Epoch 121/200\n",
            "9/9 - 0s - loss: 0.1915\n",
            "Epoch 122/200\n",
            "9/9 - 0s - loss: 0.1638\n",
            "Epoch 123/200\n",
            "9/9 - 0s - loss: 0.1388\n",
            "Epoch 124/200\n",
            "9/9 - 0s - loss: 0.1174\n",
            "Epoch 125/200\n",
            "9/9 - 0s - loss: 0.0999\n",
            "Epoch 126/200\n",
            "9/9 - 0s - loss: 0.0858\n",
            "Epoch 127/200\n",
            "9/9 - 0s - loss: 0.0741\n",
            "Epoch 128/200\n",
            "9/9 - 0s - loss: 0.0636\n",
            "Epoch 129/200\n",
            "9/9 - 0s - loss: 0.0539\n",
            "Epoch 130/200\n",
            "9/9 - 0s - loss: 0.0446\n",
            "Epoch 131/200\n",
            "9/9 - 0s - loss: 0.0363\n",
            "Epoch 132/200\n",
            "9/9 - 0s - loss: 0.0292\n",
            "Epoch 133/200\n",
            "9/9 - 0s - loss: 0.0237\n",
            "Epoch 134/200\n",
            "9/9 - 0s - loss: 0.0196\n",
            "Epoch 135/200\n",
            "9/9 - 0s - loss: 0.0164\n",
            "Epoch 136/200\n",
            "9/9 - 0s - loss: 0.0137\n",
            "Epoch 137/200\n",
            "9/9 - 0s - loss: 0.0111\n",
            "Epoch 138/200\n",
            "9/9 - 0s - loss: 0.0087\n",
            "Epoch 139/200\n",
            "9/9 - 0s - loss: 0.0064\n",
            "Epoch 140/200\n",
            "9/9 - 0s - loss: 0.0046\n",
            "Epoch 141/200\n",
            "9/9 - 0s - loss: 0.0033\n",
            "Epoch 142/200\n",
            "9/9 - 0s - loss: 0.0025\n",
            "Epoch 143/200\n",
            "9/9 - 0s - loss: 0.0020\n",
            "Epoch 144/200\n",
            "9/9 - 0s - loss: 0.0017\n",
            "Epoch 145/200\n",
            "9/9 - 0s - loss: 0.0013\n",
            "Epoch 146/200\n",
            "9/9 - 0s - loss: 8.6698e-04\n",
            "Epoch 147/200\n",
            "9/9 - 0s - loss: 4.4703e-04\n",
            "Epoch 148/200\n",
            "9/9 - 0s - loss: 1.4654e-04\n",
            "Epoch 149/200\n",
            "9/9 - 0s - loss: 2.4678e-05\n",
            "Epoch 150/200\n",
            "9/9 - 0s - loss: 6.4114e-05\n",
            "Epoch 151/200\n",
            "9/9 - 0s - loss: 1.8690e-04\n",
            "Epoch 152/200\n",
            "9/9 - 0s - loss: 3.0234e-04\n",
            "Epoch 153/200\n",
            "9/9 - 0s - loss: 3.5467e-04\n",
            "Epoch 154/200\n",
            "9/9 - 0s - loss: 3.4422e-04\n",
            "Epoch 155/200\n",
            "9/9 - 0s - loss: 3.1321e-04\n",
            "Epoch 156/200\n",
            "9/9 - 0s - loss: 3.1205e-04\n",
            "Epoch 157/200\n",
            "9/9 - 0s - loss: 3.6698e-04\n",
            "Epoch 158/200\n",
            "9/9 - 0s - loss: 4.6752e-04\n",
            "Epoch 159/200\n",
            "9/9 - 0s - loss: 5.7780e-04\n",
            "Epoch 160/200\n",
            "9/9 - 0s - loss: 6.6096e-04\n",
            "Epoch 161/200\n",
            "9/9 - 0s - loss: 6.9835e-04\n",
            "Epoch 162/200\n",
            "9/9 - 0s - loss: 6.9848e-04\n",
            "Epoch 163/200\n",
            "9/9 - 0s - loss: 6.8524e-04\n",
            "Epoch 164/200\n",
            "9/9 - 0s - loss: 6.8246e-04\n",
            "Epoch 165/200\n",
            "9/9 - 0s - loss: 6.9926e-04\n",
            "Epoch 166/200\n",
            "9/9 - 0s - loss: 7.2813e-04\n",
            "Epoch 167/200\n",
            "9/9 - 0s - loss: 7.5193e-04\n",
            "Epoch 168/200\n",
            "9/9 - 0s - loss: 7.5652e-04\n",
            "Epoch 169/200\n",
            "9/9 - 0s - loss: 7.3811e-04\n",
            "Epoch 170/200\n",
            "9/9 - 0s - loss: 7.0481e-04\n",
            "Epoch 171/200\n",
            "9/9 - 0s - loss: 6.6921e-04\n",
            "Epoch 172/200\n",
            "9/9 - 0s - loss: 6.4115e-04\n",
            "Epoch 173/200\n",
            "9/9 - 0s - loss: 6.2217e-04\n",
            "Epoch 174/200\n",
            "9/9 - 0s - loss: 6.0677e-04\n",
            "Epoch 175/200\n",
            "9/9 - 0s - loss: 5.8693e-04\n",
            "Epoch 176/200\n",
            "9/9 - 0s - loss: 5.5807e-04\n",
            "Epoch 177/200\n",
            "9/9 - 0s - loss: 5.2114e-04\n",
            "Epoch 178/200\n",
            "9/9 - 0s - loss: 4.8150e-04\n",
            "Epoch 179/200\n",
            "9/9 - 0s - loss: 4.4490e-04\n",
            "Epoch 180/200\n",
            "9/9 - 0s - loss: 4.1431e-04\n",
            "Epoch 181/200\n",
            "9/9 - 0s - loss: 3.8878e-04\n",
            "Epoch 182/200\n",
            "9/9 - 0s - loss: 3.6463e-04\n",
            "Epoch 183/200\n",
            "9/9 - 0s - loss: 3.3863e-04\n",
            "Epoch 184/200\n",
            "9/9 - 0s - loss: 3.0979e-04\n",
            "Epoch 185/200\n",
            "9/9 - 0s - loss: 2.7987e-04\n",
            "Epoch 186/200\n",
            "9/9 - 0s - loss: 2.5152e-04\n",
            "Epoch 187/200\n",
            "9/9 - 0s - loss: 2.2693e-04\n",
            "Epoch 188/200\n",
            "9/9 - 0s - loss: 2.0632e-04\n",
            "Epoch 189/200\n",
            "9/9 - 0s - loss: 1.8835e-04\n",
            "Epoch 190/200\n",
            "9/9 - 0s - loss: 1.7095e-04\n",
            "Epoch 191/200\n",
            "9/9 - 0s - loss: 1.5310e-04\n",
            "Epoch 192/200\n",
            "9/9 - 0s - loss: 1.3513e-04\n",
            "Epoch 193/200\n",
            "9/9 - 0s - loss: 1.1818e-04\n",
            "Epoch 194/200\n",
            "9/9 - 0s - loss: 1.0341e-04\n",
            "Epoch 195/200\n",
            "9/9 - 0s - loss: 9.1115e-05\n",
            "Epoch 196/200\n",
            "9/9 - 0s - loss: 8.0848e-05\n",
            "Epoch 197/200\n",
            "9/9 - 0s - loss: 7.1615e-05\n",
            "Epoch 198/200\n",
            "9/9 - 0s - loss: 6.2596e-05\n",
            "Epoch 199/200\n",
            "9/9 - 0s - loss: 5.3755e-05\n",
            "Epoch 200/200\n",
            "9/9 - 0s - loss: 4.5434e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCtVaWoWVMWJ"
      },
      "source": [
        "Модель обучена. Для того, чтобы узнать итоговые коэффициенты, воcпользуемся model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1-lyp2dVLDF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "542a774e-cb47-4f0d-bb90-6102b0c6a1ec"
      },
      "source": [
        "model.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[1.7999102]], dtype=float32), array([32.006416], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H7kG-de3iBa"
      },
      "source": [
        "В реальности эти две шкалы связаны формулой:\n",
        "$$\n",
        "F = 1.8C + 32\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNX3rwFXVnzx"
      },
      "source": [
        "Неудивительно, что мы получили правильные коэффициенты ;)\n",
        "\n",
        "\n",
        "**История обучения**\n",
        "\n",
        "Помимо обучения модели и прогресс бара, model.fit(...), возвращает полезный объект -- историю. Давайте взглянем на нее ближе."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlVie2L4VGGo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "7f565a7c-5fc0-4c5e-ab5b-fa593d80a658"
      },
      "source": [
        "import pandas as pd\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3713.952148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2557.618896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1705.239746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1151.206421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>872.101990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          loss\n",
              "0  3713.952148\n",
              "1  2557.618896\n",
              "2  1705.239746\n",
              "3  1151.206421\n",
              "4   872.101990"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj12ioIeXhGo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "262cd9ae-626e-457b-b03f-c7d4d83c6e61"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history_df.loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f571c5307f0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyOwusgP8dQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08p_QQfivsEv"
      },
      "source": [
        "На графике можно увидеть как менялся лосс на протяжении 200 эпох. Можно заметить, что обучение можно было остановить после 100 эпохи.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkQPRsMHXxEQ"
      },
      "source": [
        "##Задача классификации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHDLtJa_PyWk",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib.colors import ListedColormap, LinearSegmentedColormap, Normalize\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "np.random.seed(10)\n",
        "\n",
        "colors = ['red', \"blue\"]\n",
        "labels_cmap = ListedColormap(colors, 2)\n",
        "colors = [(1, 0, 0), (1, 1, 1), (0, 0, 1)]  # R -> W -> B\n",
        "main_cmap = LinearSegmentedColormap.from_list(\"main_scheme\", colors, N=300)\n",
        "\n",
        "def show_data(X, y):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.scatter(X[:, 0], X[:, 1], s=120, color=labels_cmap(y))\n",
        "    \n",
        "\n",
        "def show_descision_boundary(clf, limits, binary=False, X=None, y=None, n_lines=10, show_lines=False,\n",
        "                           figsize=(5, 5), ax=None):\n",
        "    xs, ys = limits\n",
        "    x_min, x_max = xs\n",
        "    y_min, y_max = ys\n",
        "    \n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
        "                         np.arange(y_min, y_max, 0.01))\n",
        "    \n",
        "    if ax is None:\n",
        "        fig = plt.figure(figsize=figsize)\n",
        "        ax = fig.add_subplot(1, 1, 1)\n",
        "    \n",
        "    if binary:\n",
        "        Z = clf.predict_class(np.c_[xx.ravel(), xx.ravel()])\n",
        "        Z = clf.predict_class(np.c_[xx.ravel(), yy.ravel()])\n",
        "        norm = Normalize(vmin=0.,vmax=1.)\n",
        "    else:\n",
        "        Z = clf(np.c_[xx.ravel(), xx.ravel()])\n",
        "        Z = clf(np.c_[xx.ravel(), yy.ravel()])\n",
        "        #if clf.prob_output:\n",
        "        #    norm = Normalize(vmin=0.,vmax=1.)\n",
        "        #else:\n",
        "        norm = Normalize(vmin=-10.,vmax=10., clip=True)\n",
        "    Z = Z.numpy() \n",
        "    Z = Z.reshape(xx.shape)\n",
        "    Z = Z.astype(np.float32)\n",
        "    \n",
        "    ax.contourf(xx, yy, Z, n_lines, alpha=0.4, cmap=main_cmap, norm=norm)\n",
        "    if show_lines:\n",
        "        cp = ax.contour(xx, yy, Z, n_lines)\n",
        "        ax.clabel(cp, inline=True, \n",
        "              fontsize=10, colors=\"green\")\n",
        "    \n",
        "    if y is not None:\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "        ax.scatter(X[:, 0], X[:, 1], s=120, color=labels_cmap(y),\n",
        "                   zorder=4)\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izD5mZpR7auO"
      },
      "source": [
        "Аналогично можно решить задачу классификации. Помните эту выборку? Мы пытались ее разделить тремя нейронами самостоятельно в самом первом модуле! Давайте теперь сделаем это с помощью Tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MUslBwSPy1y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "5d3ec8a9-a469-4058-eec0-d455b615463b"
      },
      "source": [
        "X = np.array([[10, 6], [7, 4], [6, 6], [9, 8], [10, 10],\n",
        "              [10, 4], [4, 4], [4, 6], [8, 9]])\n",
        "y = np.array([0, 1, 0, 0, 0, 1, 1, 1, 1])\n",
        "show_data(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAEyCAYAAABnD2x2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MetQo2Ik7dIR"
      },
      "source": [
        "Без каких-либо сложностей, мы преобразуем модель в модель для классификации. Для этого нужно изменить лосс функцию и функцию активации последнего слоя."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEs6b7mlQg5d"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(4, input_shape=(2,), activation=\"sigmoid\"))\n",
        "model.add(tf.keras.layers.Dense(1)) # мы хотим визуализировать логиты, поэтому без активации\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.05) \n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True) # лосс -- с логитами"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU2ndXHCb5Dm"
      },
      "source": [
        "При компиляции модели добавим еще одно поле -- **metrics**. Метрики не влияют на обучение, но очень полезны для его контроля. Например, обучая классификатор удобно смотреть не только на лосс, но и на точность."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wup7_mqBb1Hr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e55fee6-0493-4b97-a918-3e56ac50c572"
      },
      "source": [
        "model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"]) # для дополнительного контроля \n",
        "                                                                    #-- просим сообщать не только лосс, но и точность.\n",
        "history = model.fit(X, y, epochs=100, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0816 09:43:30.644775 140013169076096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "9/9 - 0s - loss: 0.7260 - acc: 0.4444\n",
            "Epoch 2/100\n",
            "9/9 - 0s - loss: 0.6919 - acc: 0.4444\n",
            "Epoch 3/100\n",
            "9/9 - 0s - loss: 0.6806 - acc: 0.4444\n",
            "Epoch 4/100\n",
            "9/9 - 0s - loss: 0.6831 - acc: 0.4444\n",
            "Epoch 5/100\n",
            "9/9 - 0s - loss: 0.6832 - acc: 0.5556\n",
            "Epoch 6/100\n",
            "9/9 - 0s - loss: 0.6776 - acc: 0.5556\n",
            "Epoch 7/100\n",
            "9/9 - 0s - loss: 0.6693 - acc: 0.5556\n",
            "Epoch 8/100\n",
            "9/9 - 0s - loss: 0.6617 - acc: 0.5556\n",
            "Epoch 9/100\n",
            "9/9 - 0s - loss: 0.6569 - acc: 0.4444\n",
            "Epoch 10/100\n",
            "9/9 - 0s - loss: 0.6546 - acc: 0.4444\n",
            "Epoch 11/100\n",
            "9/9 - 0s - loss: 0.6536 - acc: 0.4444\n",
            "Epoch 12/100\n",
            "9/9 - 0s - loss: 0.6522 - acc: 0.4444\n",
            "Epoch 13/100\n",
            "9/9 - 0s - loss: 0.6500 - acc: 0.5556\n",
            "Epoch 14/100\n",
            "9/9 - 0s - loss: 0.6473 - acc: 0.5556\n",
            "Epoch 15/100\n",
            "9/9 - 0s - loss: 0.6448 - acc: 0.5556\n",
            "Epoch 16/100\n",
            "9/9 - 0s - loss: 0.6436 - acc: 0.6667\n",
            "Epoch 17/100\n",
            "9/9 - 0s - loss: 0.6429 - acc: 0.6667\n",
            "Epoch 18/100\n",
            "9/9 - 0s - loss: 0.6410 - acc: 0.6667\n",
            "Epoch 19/100\n",
            "9/9 - 0s - loss: 0.6374 - acc: 0.6667\n",
            "Epoch 20/100\n",
            "9/9 - 0s - loss: 0.6335 - acc: 0.6667\n",
            "Epoch 21/100\n",
            "9/9 - 0s - loss: 0.6301 - acc: 0.6667\n",
            "Epoch 22/100\n",
            "9/9 - 0s - loss: 0.6270 - acc: 0.6667\n",
            "Epoch 23/100\n",
            "9/9 - 0s - loss: 0.6235 - acc: 0.6667\n",
            "Epoch 24/100\n",
            "9/9 - 0s - loss: 0.6191 - acc: 0.6667\n",
            "Epoch 25/100\n",
            "9/9 - 0s - loss: 0.6141 - acc: 0.6667\n",
            "Epoch 26/100\n",
            "9/9 - 0s - loss: 0.6095 - acc: 0.6667\n",
            "Epoch 27/100\n",
            "9/9 - 0s - loss: 0.6062 - acc: 0.6667\n",
            "Epoch 28/100\n",
            "9/9 - 0s - loss: 0.6036 - acc: 0.6667\n",
            "Epoch 29/100\n",
            "9/9 - 0s - loss: 0.5998 - acc: 0.6667\n",
            "Epoch 30/100\n",
            "9/9 - 0s - loss: 0.5947 - acc: 0.6667\n",
            "Epoch 31/100\n",
            "9/9 - 0s - loss: 0.5894 - acc: 0.6667\n",
            "Epoch 32/100\n",
            "9/9 - 0s - loss: 0.5851 - acc: 0.6667\n",
            "Epoch 33/100\n",
            "9/9 - 0s - loss: 0.5810 - acc: 0.6667\n",
            "Epoch 34/100\n",
            "9/9 - 0s - loss: 0.5762 - acc: 0.6667\n",
            "Epoch 35/100\n",
            "9/9 - 0s - loss: 0.5710 - acc: 0.6667\n",
            "Epoch 36/100\n",
            "9/9 - 0s - loss: 0.5662 - acc: 0.6667\n",
            "Epoch 37/100\n",
            "9/9 - 0s - loss: 0.5614 - acc: 0.6667\n",
            "Epoch 38/100\n",
            "9/9 - 0s - loss: 0.5555 - acc: 0.6667\n",
            "Epoch 39/100\n",
            "9/9 - 0s - loss: 0.5495 - acc: 0.6667\n",
            "Epoch 40/100\n",
            "9/9 - 0s - loss: 0.5441 - acc: 0.6667\n",
            "Epoch 41/100\n",
            "9/9 - 0s - loss: 0.5387 - acc: 0.6667\n",
            "Epoch 42/100\n",
            "9/9 - 0s - loss: 0.5326 - acc: 0.6667\n",
            "Epoch 43/100\n",
            "9/9 - 0s - loss: 0.5261 - acc: 0.6667\n",
            "Epoch 44/100\n",
            "9/9 - 0s - loss: 0.5199 - acc: 0.6667\n",
            "Epoch 45/100\n",
            "9/9 - 0s - loss: 0.5140 - acc: 0.6667\n",
            "Epoch 46/100\n",
            "9/9 - 0s - loss: 0.5076 - acc: 0.6667\n",
            "Epoch 47/100\n",
            "9/9 - 0s - loss: 0.5012 - acc: 0.6667\n",
            "Epoch 48/100\n",
            "9/9 - 0s - loss: 0.4950 - acc: 0.6667\n",
            "Epoch 49/100\n",
            "9/9 - 0s - loss: 0.4885 - acc: 0.6667\n",
            "Epoch 50/100\n",
            "9/9 - 0s - loss: 0.4820 - acc: 0.7778\n",
            "Epoch 51/100\n",
            "9/9 - 0s - loss: 0.4757 - acc: 0.7778\n",
            "Epoch 52/100\n",
            "9/9 - 0s - loss: 0.4694 - acc: 0.7778\n",
            "Epoch 53/100\n",
            "9/9 - 0s - loss: 0.4628 - acc: 0.7778\n",
            "Epoch 54/100\n",
            "9/9 - 0s - loss: 0.4563 - acc: 0.7778\n",
            "Epoch 55/100\n",
            "9/9 - 0s - loss: 0.4500 - acc: 0.7778\n",
            "Epoch 56/100\n",
            "9/9 - 0s - loss: 0.4437 - acc: 0.7778\n",
            "Epoch 57/100\n",
            "9/9 - 0s - loss: 0.4373 - acc: 0.7778\n",
            "Epoch 58/100\n",
            "9/9 - 0s - loss: 0.4310 - acc: 0.7778\n",
            "Epoch 59/100\n",
            "9/9 - 0s - loss: 0.4248 - acc: 0.7778\n",
            "Epoch 60/100\n",
            "9/9 - 0s - loss: 0.4186 - acc: 0.7778\n",
            "Epoch 61/100\n",
            "9/9 - 0s - loss: 0.4125 - acc: 0.7778\n",
            "Epoch 62/100\n",
            "9/9 - 0s - loss: 0.4063 - acc: 0.7778\n",
            "Epoch 63/100\n",
            "9/9 - 0s - loss: 0.4002 - acc: 0.7778\n",
            "Epoch 64/100\n",
            "9/9 - 0s - loss: 0.3943 - acc: 0.7778\n",
            "Epoch 65/100\n",
            "9/9 - 0s - loss: 0.3883 - acc: 0.7778\n",
            "Epoch 66/100\n",
            "9/9 - 0s - loss: 0.3824 - acc: 0.7778\n",
            "Epoch 67/100\n",
            "9/9 - 0s - loss: 0.3765 - acc: 0.7778\n",
            "Epoch 68/100\n",
            "9/9 - 0s - loss: 0.3707 - acc: 0.7778\n",
            "Epoch 69/100\n",
            "9/9 - 0s - loss: 0.3650 - acc: 0.8889\n",
            "Epoch 70/100\n",
            "9/9 - 0s - loss: 0.3593 - acc: 0.8889\n",
            "Epoch 71/100\n",
            "9/9 - 0s - loss: 0.3536 - acc: 0.8889\n",
            "Epoch 72/100\n",
            "9/9 - 0s - loss: 0.3480 - acc: 0.8889\n",
            "Epoch 73/100\n",
            "9/9 - 0s - loss: 0.3425 - acc: 0.8889\n",
            "Epoch 74/100\n",
            "9/9 - 0s - loss: 0.3370 - acc: 0.8889\n",
            "Epoch 75/100\n",
            "9/9 - 0s - loss: 0.3316 - acc: 0.8889\n",
            "Epoch 76/100\n",
            "9/9 - 0s - loss: 0.3262 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "9/9 - 0s - loss: 0.3209 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "9/9 - 0s - loss: 0.3156 - acc: 1.0000\n",
            "Epoch 79/100\n",
            "9/9 - 0s - loss: 0.3104 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "9/9 - 0s - loss: 0.3052 - acc: 1.0000\n",
            "Epoch 81/100\n",
            "9/9 - 0s - loss: 0.3001 - acc: 1.0000\n",
            "Epoch 82/100\n",
            "9/9 - 0s - loss: 0.2951 - acc: 1.0000\n",
            "Epoch 83/100\n",
            "9/9 - 0s - loss: 0.2901 - acc: 1.0000\n",
            "Epoch 84/100\n",
            "9/9 - 0s - loss: 0.2852 - acc: 1.0000\n",
            "Epoch 85/100\n",
            "9/9 - 0s - loss: 0.2803 - acc: 1.0000\n",
            "Epoch 86/100\n",
            "9/9 - 0s - loss: 0.2755 - acc: 1.0000\n",
            "Epoch 87/100\n",
            "9/9 - 0s - loss: 0.2707 - acc: 1.0000\n",
            "Epoch 88/100\n",
            "9/9 - 0s - loss: 0.2660 - acc: 1.0000\n",
            "Epoch 89/100\n",
            "9/9 - 0s - loss: 0.2614 - acc: 1.0000\n",
            "Epoch 90/100\n",
            "9/9 - 0s - loss: 0.2568 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "9/9 - 0s - loss: 0.2523 - acc: 1.0000\n",
            "Epoch 92/100\n",
            "9/9 - 0s - loss: 0.2478 - acc: 1.0000\n",
            "Epoch 93/100\n",
            "9/9 - 0s - loss: 0.2434 - acc: 1.0000\n",
            "Epoch 94/100\n",
            "9/9 - 0s - loss: 0.2391 - acc: 1.0000\n",
            "Epoch 95/100\n",
            "9/9 - 0s - loss: 0.2348 - acc: 1.0000\n",
            "Epoch 96/100\n",
            "9/9 - 0s - loss: 0.2306 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "9/9 - 0s - loss: 0.2264 - acc: 1.0000\n",
            "Epoch 98/100\n",
            "9/9 - 0s - loss: 0.2224 - acc: 1.0000\n",
            "Epoch 99/100\n",
            "9/9 - 0s - loss: 0.2183 - acc: 1.0000\n",
            "Epoch 100/100\n",
            "9/9 - 0s - loss: 0.2144 - acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8VXug0TRKl1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "4685e371-58ec-4e79-c27e-4fa2bf80eefb"
      },
      "source": [
        "limits = [[-1, 11], [-1, 11]]\n",
        "\n",
        "show_descision_boundary(limits=limits, clf=model, binary=False,\n",
        "                                X=X,\n",
        "                                y=y, \n",
        "                                n_lines=50,\n",
        "                                show_lines=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAEyCAYAAABnD2x2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngiCMDCI8QRBGBhGeIAgjw/8HxuFq1DVzxfMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDC9kIa6b0KN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "3a3d4d74-ef44-4af7-8ecf-5fa165d41cee"
      },
      "source": [
        "pd.DataFrame(history.history).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.726030</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.691873</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.680570</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.683061</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.683180</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss       acc\n",
              "0  0.726030  0.444444\n",
              "1  0.691873  0.444444\n",
              "2  0.680570  0.444444\n",
              "3  0.683061  0.444444\n",
              "4  0.683180  0.555556"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QatTGrh3xI3m"
      },
      "source": [
        "## Рекомендации к практическому заданию\n",
        "В следующем практическом задании перед вами будет стоять задача обучения сетей для синтетических данных. Для этого вам нужно будет подобрать самим количество слоев, количество нейронов и скорость обучения. **Как это сделать?** К сожалению, однозначного ответа на этот вопрос нет. \n",
        "\n",
        "Чем сложнее задача, тем сложнее должна быть архитектура. Сложность архитектуры зависит от количества слоев и нейронов. Задачи, которые вас ждут с ближайшей практике, данные не слишком сложные -- поэтому не переусердствуйте. *Начните с одного слоя, понаблюдайте, как изменяется точность, добавьте еще один, если понадобится. Экспериментируйте!*\n",
        "\n",
        "Но это не единственный рычаг, который можно двигать. Еще есть скорость обучения. Если вы замечаете при обучении, что ошибка не меняется, но архитектура должна справиться, то возможно скорость обучения слишком маленькая. Обычно она находится в диапазоне 0.0001-0.1.\n",
        "\n",
        "В реальных задачах глубина сети, количество нейронов, скорость обучения -- это гиперпараметры, которые нужно подбирать наблюдая за качеством на валидационной выборкой.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_20rdANCX7v"
      },
      "source": [
        "#Заключение\n",
        "В этом уроке мы научились:\n",
        "\n",
        "\n",
        "1.   Определять лосс функцию\n",
        "2.   Определять оптимизатор\n",
        "3.   Компилировать и обучать модель для задачи классификации и регрессии.\n",
        "\n",
        "Теперь вы можете перейти к практике для закрепления материала: [ссылка](https://colab.research.google.com/drive/11pzWQSauLzuoUPyRW10zV1p7o4NKMVB7).\n",
        "\n"
      ]
    }
  ]
}