{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Реализация SSD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB7KH79cllBx"
      },
      "source": [
        "# Реализация SSD\n",
        "В это практическом уроке мы рассмотрим упрощённый пример реализации архитектуры SSD (Single Shot Multibox Detector). Цель урока -- разобраться с тем, как работает инференс в архитектуре SSD. Обучение SDD -- отдельный сложный вопрос, которы выходит за рамки данного урока."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTkwGr6WmI-F"
      },
      "source": [
        "### Загрузка необходимых библиотек\n",
        "Здесь мы загружаем различне библиотеки, включая TensoFlow.\n",
        "\n",
        "В TensorFlow инициируем режим жадного (eager) выполнения и проверяем версию (должна быть 1.14)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMcG-Lgg-ODD"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "#tf.enable_eager_execution()\n",
        "print('TensorFlow version:', tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SdSWYn0mJ1k"
      },
      "source": [
        "### Модель SSD\n",
        "\n",
        "Давайте реализуем класс, соответствующий модели SSD. Если предположить, что такая модель уже обучена, предсказание с её помощью сделать довольно просто.\n",
        "\n",
        "Наша модель будет состоять из некоторого набора свёртчоных и пулинг слоёв, с помощью которых мы получаем несколько промежуточных карт признаков, соответствующих различным масштабам (`feat1`, `feat2`, `feat3`). Далее для каждого такого масштаба запускается детектор, который по сути является просто свёрточным слоем, задача которого предсказать классы и координаты боксов (всё это для каждого дефолт-бокса). Каждому пространственному пикселю тензора, который подаёдтся на вход в детектор соовтетствует несколько дефолт боксов (`num_def_boxes`), относительно которых мы и имщем объекты на картинке.\n",
        "\n",
        "Итого, каждый детектор для одного пространственного пикселя карт признаков должен предсказать вектор размерности `N*(4+C)`, где N - кол-во дефолт боксов, C - кол-во классов.\n",
        "\n",
        "Для наглядности можно раздеить каждый детектор на два параллельных свёрточных слоя: `conv_cls_i`, ответственный за классификацию дефолт-боксов (кол-во выходных каналов `N*C`), и `conv_loc_i`, ответственный за локализацию (кол-во выходных каналов `N*4`). \n",
        "\n",
        "То, как устроены дефолт-боксы (их расположение и размеры) имеет значение во время обучения, но не нужно для инференса. Нам нужно лишь знать, сколько дефолт-боксов есть в нашей модели.\n",
        "\n",
        "В конце соединим предсказания со всех детекторов.\n",
        "\n",
        "**[ЗАДАНИЕ 1]** Вопрос: Какое максимальное количество боксов может предсказать такая модель, если размер входной картинки равен будет 128x128, а num_def_boxes=3?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFEQfjBM-ODH"
      },
      "source": [
        "class SSD(tf.keras.Model):\n",
        "    def __init__(self, num_classes, num_def_boxes):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        " \n",
        "        # Слои для извлечения признаков\n",
        "        self.conv1 = tf.keras.layers.Conv2D(32, (5, 5), activation=tf.nn.relu, padding='same')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(32, (5, 5), activation=tf.nn.relu, padding='same')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(64, (5, 5), activation=tf.nn.relu, padding='same')\n",
        "        self.conv4 = tf.keras.layers.Conv2D(64, (5, 5), activation=tf.nn.relu, padding='same')\n",
        "        self.conv5 = tf.keras.layers.Conv2D(128, (5, 5), activation=tf.nn.relu, padding='same')\n",
        "        self.conv6 = tf.keras.layers.Conv2D(128, (5, 5), activation=tf.nn.relu, padding='same')\n",
        "        \n",
        "        # Классификационные части детекторов (отдельный детектор для каждого масштаба)\n",
        "        # Для каждого пикселя карт признаков предсказываются \n",
        "        # распределения вероятностей для всех дефолт боксов\n",
        "        self.conv_cls1 = tf.keras.layers.Conv2D(num_def_boxes*num_classes, (3, 3), activation=tf.nn.relu, padding='same')\n",
        "        self.conv_cls2 = tf.keras.layers.Conv2D(num_def_boxes*num_classes, (3, 3), activation=tf.nn.relu, padding='same')\n",
        "        self.conv_cls3 = tf.keras.layers.Conv2D(num_def_boxes*num_classes, (3, 3), activation=tf.nn.relu, padding='same')\n",
        "        \n",
        "        # Локализационные части детекторов  (отдельный детектор для каждого масштаба)\n",
        "        # Для каждого пикселя карт признаков предсказываются \n",
        "        # координаты всех дефолт боксов\n",
        "        self.conv_loc1 = tf.keras.layers.Conv2D(num_def_boxes*4, (3, 3), activation=tf.nn.relu, padding='same')\n",
        "        self.conv_loc2 = tf.keras.layers.Conv2D(num_def_boxes*4, (3, 3), activation=tf.nn.relu, padding='same')\n",
        "        self.conv_loc3 = tf.keras.layers.Conv2D(num_def_boxes*4, (3, 3), activation=tf.nn.relu, padding='same')        \n",
        "        \n",
        "        self.pool = tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')\n",
        "\n",
        "    # Переход к тензору размера (batch, num_boxes, num_classes)\n",
        "    # batch - кол-во образцов в батче\n",
        "    # num_boxes - количество всех боксов для данного масштаба\n",
        "    # num_classes - количество классов\n",
        "    def reshape_cls(self, pred_cls):\n",
        "        pred_cls = tf.transpose(pred_cls, (0, 3, 1, 2))\n",
        "        pred_cls = tf.reshape(pred_cls, (pred_cls.shape[0], self.num_classes, -1))\n",
        "        pred_cls = tf.transpose(pred_cls, (0, 2, 1))\n",
        "        return pred_cls\n",
        "      \n",
        "    # Переход к тензору размера (batch, num_boxes, 4)\n",
        "    # batch - кол-во образцов в батче\n",
        "    # num_boxes - количество всех боксов для данного масштаба\n",
        "    def reshape_loc(self, pred_loc):\n",
        "        pred_loc = tf.transpose(pred_loc, (0, 3, 1, 2))\n",
        "        pred_loc = tf.reshape(pred_loc, (pred_loc.shape[0], 4, -1))\n",
        "        pred_loc = tf.transpose(pred_loc, (0, 2, 1))    \n",
        "        return pred_loc\n",
        "        \n",
        "    def call(self, x):\n",
        "        \n",
        "        # Извлечение признаков\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        feat1 = self.pool(out)\n",
        "        out = self.conv3(feat1)\n",
        "        out = self.conv4(out)\n",
        "        feat2 = self.pool(out)\n",
        "        out = self.conv5(feat2)\n",
        "        out = self.conv6(out)\n",
        "        feat3 = self.pool(out)\n",
        "        \n",
        "        # Применение детектора: классификационная часть\n",
        "        pred_cls1 = self.conv_cls1(feat1)\n",
        "        pred_cls2 = self.conv_cls2(feat2)\n",
        "        pred_cls3 = self.conv_cls3(feat3)\n",
        "        \n",
        "        # Применение детектора: локализационная часть\n",
        "        pred_loc1 = self.conv_loc1(feat1)\n",
        "        pred_loc2 = self.conv_loc2(feat2)\n",
        "        pred_loc3 = self.conv_loc3(feat3)\n",
        "        \n",
        "        # Для каждого масштаба переход к тензору размера (batch, num_boxes, num_classes)\n",
        "        # в тензоре размера (batch, num_boxes, num_classes)\n",
        "        pred_cls1 = self.reshape_cls(pred_cls1)\n",
        "        pred_cls2 = self.reshape_cls(pred_cls2)\n",
        "        pred_cls3 = self.reshape_cls(pred_cls3)\n",
        "        \n",
        "        # Для каждого масштаба получение тензора с координатами всех боксов \n",
        "        # в тензоре размера (batch, num_boxes, 4)\n",
        "        pred_loc1 = self.reshape_loc(pred_loc1)\n",
        "        pred_loc2 = self.reshape_loc(pred_loc2)\n",
        "        pred_loc3 = self.reshape_loc(pred_loc3)\n",
        "        \n",
        "        # Объединение всех детекций для разнцх масштабов\n",
        "        pred_cls = tf.concat([pred_cls1, pred_cls2, pred_cls3], axis=1)\n",
        "        pred_loc = tf.concat([pred_loc1, pred_loc2, pred_loc3], axis=1)\n",
        "                \n",
        "        return pred_cls, pred_loc\n",
        "        \n",
        "model = SSD(num_classes=11, num_def_boxes=3)        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CptuQjaXvTLU"
      },
      "source": [
        "### Post-Processing\n",
        "Сейчас наша SSD модель выдает ответы для всех возможных дефолт-боксов. В полной SSD архитектуре нужны две дополнительные стадии фильтрации: удаление боксов, соответствующих классу \"фон\" и удаление \"дубликатов\" с помощью метода Non-Maximum Suppression.\n",
        "\n",
        "**[ЗАДАНИЕ 2]** Реализуйте первую фильтрацию предсказаний SSD модели -- чтобы остались только боксы, соответствующие объекту (нужно отбросить боксы, соответствующие классу \"фон\").\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd2yLjYDv3NA"
      },
      "source": [
        "### Базовая модель\n",
        "Архитектура SSD может быть реализована поверх любой произвольной модели CNN. Такая модель иногда называется \"Базовая модель\". Например, если есть CNN модель ResNet-101, то можно реализовать \"SSD на основе ResNet-101\".\n",
        "\n",
        "**[ЗАДАНИЕ 3]** Ниже приведена реализация классификационной архитектуры VGG-16 (просто для ознакомления). Реализуйте архитектуру детектирования объектов SSD на основе VGG-16 (по аналогии с примеров в начале). Используйте 4 различных уровня (масштаба) признаков для детекторов (выберите соответствувющие тензоры самостоятельно)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLLcdmzrrMgp"
      },
      "source": [
        "vgg = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dense(1000, activation='softmax'),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}