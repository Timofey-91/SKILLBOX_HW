{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Реализация Fast R-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEViq_XLX59c"
      },
      "source": [
        "# Реализация Fast R-CNN\n",
        "В этом практическом уроке мы реализуем метод Fast R-CNN. Он будет во многом  похож на R-CNN. Однако, если в случае R-CNN пропозалы и нейросетевой классификатор были двумя независимыми вещами, то в случае Fast R-CNN пропозалы будут использоваться внутри сети, которая делает предсказание."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYQiR132Y6pc"
      },
      "source": [
        "### Загрузка необходимых библиотек\n",
        "Здесь мы загружаем различне библиотеки, включая TensoFlow.\n",
        "\n",
        "В TensorFlow инициируем режим жадного (eager) выполнения и проверяем версию (должна быть 1.14)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqmWvR509bUA"
      },
      "source": [
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "print('TensorFlow version:', tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3Z9CItwZMwd"
      },
      "source": [
        "## Архитектура Fast R-CNN\n",
        "Перейдем сразу к архитектуре Fast R-CNN. Все остальыне части пайплайна не отличаются от R-CNN. Внутри Fast R-CNN по-прежнему будет находиться свёрточная нейросеть, которую необходимо обучить на задачу классификации, так же как в R-CNN. \n",
        "\n",
        "Однако инференс (детектирование) в Fast R-CNN работает иначе. Вместо того, чтобы запускать классификатор отдельно для каждого пропозала на картинке, мы сначала запускаем первую часть сети, которая извлекает признаки для всей картинки (один раз). А затем отображаем пропозалы в это признаковое пространство, вырезаем соответствующие кусочки, делаем ROI Pooling и прогоняем результат через вторую (классификационную) часть нейросети.\n",
        "\n",
        "Получается, что у нас есть два режима работа модели: в режиме обучения наша модель работает (обучается) как простой классификатор, а в режиме детектирования модель работает описанным выше хитрым способом. В обоих режимах нам нужно использовать прямое распространение (в обучении это часть всего процесса), которое реализуется функцией `call()`. Таким образом нам придётся как-то организовать два типа поведения в рамках одной модели. Для этого давайте просто в функции `call()`, где и происходит прямое распространение, сделаем условное ветвление: если на вход пришли пропозалы, значит работаем в режиме инференса (предсказание), а если пропозалов нет, значит работаем в режиме обучения (как обычный классификатор). По сути, у нас получится динамический граф -- вызов тех или иных слоёв зависит от входных данных.\n",
        "\n",
        "В режиме предсказания сначала применим свёрточные и пулинг слои. Затем получим координаты пропозалов в признаковом пространстве. Так как размерность признакового пространства уменьшилась по сравнению с входной картинкой из-за пулинга, то и пропозалы должны пропорционально уменьшиться. А так как у нас координаты пропозалов обычно задаются в относительнеых величинах, значит мы просто будем использовать размеры карт признаков (`feat.shape`) для перехода к абсолютным координатам. После этого вырезаем соответствующи кусочки из карт признаков (берём все каналы) и после приведения к нужному размеру (`roi_pool_size`) подаём этот тензор в полносвязные слои.\n",
        "\n",
        "Однако, сделаем некоторое упрощение: вместо ROI Pooling, будем использовать похожую по эффекту операцию: простую билинейную интерполяцию -- то есть просто приводить тензоры к нужному фиксированному размеру с помощью resize.\n",
        "\n",
        "Результаты всех предсказаний (если предсказанный клас не \"фон\") запишем в выходной список -- аналогично тому, как это было в R-CNN методе.\n",
        "\n",
        "**[ЗАДАНИЕ 1]** Вопрос: Почему `roi_pool_size = (7, 7)`? При условии, что пространственные размеры картинок в классификационном датасете, на котором мы будем обучать эту модель - (28, 28)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VsYyC8M9bUr"
      },
      "source": [
        "NUM_CLASSES = 11\n",
        "\n",
        "class Model(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        self.conv1 = tf.keras.layers.Conv2D(32, (5, 5), activation='relu', padding='same')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, (5, 5), activation='relu', padding='same')\n",
        "        self.fc1 = tf.keras.layers.Dense(256, activation='relu')\n",
        "        self.fc2 = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "        self.max_pool = tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')\n",
        "        \n",
        "    def call(self, inp, proposals=None):\n",
        "        \n",
        "        if proposals is None: # Режим обучения\n",
        "          \n",
        "            out = self.conv1(inp)\n",
        "            out = self.max_pool(out)\n",
        "            out = self.conv2(out)\n",
        "            out = self.max_pool(out)\n",
        "            out = tf.layers.flatten(out)\n",
        "            out = self.fc1(out)\n",
        "            out = self.fc2(out)\n",
        "            return out\n",
        "          \n",
        "        else: # Режим предсказания\n",
        "          \n",
        "            assert inp.shape[0] == 1 # Только batch size = 1\n",
        "            predictions = []\n",
        "            roi_pool_size = (7, 7)\n",
        "            \n",
        "            # Извлечение признаков из всей картинки\n",
        "            out = self.conv1(inp)\n",
        "            out = self.max_pool(out)\n",
        "            out = self.conv2(out)\n",
        "            feat = self.max_pool(out)\n",
        "            \n",
        "            # Для каждого пропозала\n",
        "            for proposal in proposals:\n",
        "                \n",
        "                # Отображение координат пространства изображения \n",
        "                # в координаты пространства признаков\n",
        "                ry, rx, rh, rw = proposal        \n",
        "                box_y = int(round(ry * int(feat.shape[1])))\n",
        "                box_x = int(round(rx * int(feat.shape[2])))\n",
        "                box_w = int(round(rw * int(feat.shape[2])))\n",
        "                box_h = int(round(rh * int(feat.shape[1])))\n",
        "                \n",
        "                # Вырезаем признаки, относящиеся к пропозалу\n",
        "                feat_sub = feat[:, box_y:box_y+box_h, box_x:box_x+box_w, :]\n",
        "                \n",
        "                # Аналог ROI Pooling\n",
        "                feat_pooled = tf.image.resize(\n",
        "                    feat_sub, \n",
        "                    (roi_pool_size[0], roi_pool_size[1]), \n",
        "                    tf.image.ResizeMethod.BILINEAR)\n",
        "                \n",
        "                # Финальная классификация\n",
        "                out = tf.layers.flatten(feat_pooled)\n",
        "                out = self.fc1(out)\n",
        "                out = self.fc2(out)\n",
        "                \n",
        "                # Фильтрация класса \"фон\"\n",
        "                assert out.shape[0] == 1 # Только batch size = 1\n",
        "                pred = out[0]\n",
        "                pred_cls = np.argmax(pred)\n",
        "                if pred_cls != 10:\n",
        "                    predictions.append([pred_cls] + proposal)               \n",
        "        \n",
        "            return predictions\n",
        "    \n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGQ93tiScIKf"
      },
      "source": [
        "### Обучение Fast R-CNN\n",
        "Все остальные части пйплнайна обучения такие же, как и для R-CNN\n",
        "\n",
        "**[ЗАДАНИЕ 2]**: Подготовьте необходимые данные: `train_x_cls`, `train_y_cls`, `test_x_det`, `test_y_det`, `test_proposals` точно так же, как это было в уроке про R-CNN. Обучите модель `model` на классификационном датасете, по аналогии с тем, как мы это делали для R-CNN. В режиме обучения в функцию `call()` не будут передаваться пропозалы, поэтому модель будет вести себя как обычный классификатор."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9NIfKiac1Zk"
      },
      "source": [
        "### Запуск детектирования объектов с помощью Fast R-CNN\n",
        "Для запуска этого и последующих блоков понядобятся функции, реализованные в уроке, посвящённом R-CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy8IwxSH9bU5"
      },
      "source": [
        "idx = random.randint(0, 1000)\n",
        "img = test_x_det[idx]\n",
        "labels_true = test_y_det[idx]\n",
        "proposals_img = test_proposals[idx]\n",
        "\n",
        "preds = model(img[None, ...], proposals_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eID3FN1tdbFc"
      },
      "source": [
        "### Визуализация Ground-Truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqc-RH9g9bU7"
      },
      "source": [
        "show_prediction(img, labels_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUkmyPZeddad"
      },
      "source": [
        "### Визуализация пропозалов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLcezKdM9bU9"
      },
      "source": [
        "show_proposals(img, proposals_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuGi08t_dgS5"
      },
      "source": [
        "### Визуализация детекций Fast R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-pf_qMx9bU_"
      },
      "source": [
        "show_prediction(img, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4Rfn08FecAk"
      },
      "source": [
        "### Дополнительное задание\n",
        "**[ЗАДАНИЕ 3]** Позапускайте Fast R-CNN для разных изображений из тестовой выборки, оцените качество. Попробуйте улучшить Fast R-CNN за счёт подбора гиперпараметров модели и обучения."
      ]
    }
  ]
}