{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prepare_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddfo42JUxiv2"
      },
      "source": [
        "\n",
        "# TensorFlow Object Detection: Подготовка данных для обучения\n",
        "\n",
        "https://github.com/tensorflow/models/tree/master/research/object_detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNXSkTUskE2G"
      },
      "source": [
        "### Монтирование Google Drive\n",
        "Для данного демо нам понадобятся несколько ноутбуков, которые должны работать с одними и теме же данными. Поэтому, чтобы все ноутбуки имели доступ к нужным данным, нам будет необходимо подключить диск Google Drive и сохранять все данные на нём (включая данные, скачанные из интернета).\n",
        "\n",
        "Для монтирования диска нужно выполнить данный блок, перейти по ссылке, получить код, скопировать его в поле ниже (в этом блоке) и нажать Enter\n",
        "\n",
        "После монтирования диск будет находиться здесь: `/content/drive/My Drive`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4GE9oRXhvYX",
        "outputId": "96b0e2cb-fa0c-4c7e-99f9-f55de03be46d"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwmROL4Bho-r",
        "outputId": "f07863c4-4625-4ad4-d1b5-108690360f5d"
      },
      "source": [
        "pip install tf_slim"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 352 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHW9rFr1l8Nk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "127bc735-b40b-412e-92f2-ad0874e9b199"
      },
      "source": [
        "pip install lvis"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.23)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.3.1)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.1)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAsG6Dc8kuQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ec43f5-df57-4fdc-9ece-7f5e6c868267"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnnmVH__kx5B"
      },
      "source": [
        "### Рабочая директория\n",
        "Все данные будем хранить в директории `/content/drive/My Drive/tf_od_demo` (TensorFlow Object Detection Demo)\n",
        "\n",
        "При первом запуске создадим директорию (если её еще не существует), в противном случае надо заменить True на False.\n",
        "\n",
        "При последующих подключениях к диску (в том числе в других ноутбуках) директорию создавать не надо, в ней уже будут сохранены все данные, которые мы туда поместили."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khoZUcm6lrbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d399845-3dc6-437a-d47a-100c67131350"
      },
      "source": [
        "if True:\n",
        "    !mkdir \"/content/drive/My Drive/tf_od_demo\"\n",
        "%cd \"/content/drive/My Drive/tf_od_demo\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/tf_od_demo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk53xwHtalrN"
      },
      "source": [
        "### Подготовка библиотеки `object_detection`\n",
        "Библиотека `object_detection` находится в репозитории `tensorflow/models` в разделе `research`\n",
        "\n",
        "Необходимо склонировать код библиотеки и сконфигурировать модели (сбилдить прото модели).\n",
        "\n",
        "Этот шаг нужно сделать один раз (не повторять, если папка `models` уже находится в текущей директории).\n",
        "\n",
        "Подробнее: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPueN9mCBpHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95c409f-ce05-47a9-9b56-5fa647ef168a"
      },
      "source": [
        "if True:\n",
        "  \n",
        "    !git clone https://github.com/tensorflow/models\n",
        "    !cd models/research && protoc object_detection/protos/*.proto --python_out=.\n",
        "    !cd models/research && export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim && python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 59177, done.\u001b[K\n",
            "remote: Counting objects: 100% (648/648), done.\u001b[K\n",
            "remote: Compressing objects: 100% (304/304), done.\u001b[K\n",
            "remote: Total 59177 (delta 412), reused 558 (delta 335), pack-reused 58529\u001b[K\n",
            "Receiving objects: 100% (59177/59177), 573.64 MiB | 17.73 MiB/s, done.\n",
            "Resolving deltas: 100% (41044/41044), done.\n",
            "Checking out files: 100% (2579/2579), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFCMljCEx9VW"
      },
      "source": [
        "### Загрузка библиотек\n",
        "Загрузка TensorFlow и других библиотек. Кроме того, загрузка модуля `dataset_util` из пакета `object_detection`, который будет нужен для создания датасета в нужном формате."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH8kQ2q30B03"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, 'models/research')\n",
        "\n",
        "from object_detection.utils import dataset_util"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZmalcqDcwWG"
      },
      "source": [
        "### Функция для создания одного обучающего образца\n",
        "В этой функции создаётся экземпляр класса `tf.train.Example`, который соответствует одной обучающей картике. Ей могут соответствовать несколько ground-truth баундинг боксов. Однако, конкретно в данном примере на картинке есть строго один бокс. В противном случае списки `xmins`, `xmaxs`, `ymins`, `ymaxs`, `classes_text`, `classes` должны иметь соответствующее количество элементов ( = кол-ву боксов на данной картинке).\n",
        "\n",
        "Создавать экземпляры класса `tf.train.Example` можно произвольным способом. В данном примере на вход в функцию подаётся строка из CSV файла (`annot.csv`). Главное -- заполнить соовтестсвующие поля словаре `feature={...}`\n",
        "\n",
        "Подробнее: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvz1hSw70OyQ"
      },
      "source": [
        "def create_tf_example(example):\n",
        "  \n",
        "    img_fpath = os.path.join('my_data2', example.id)\n",
        "    img = Image.open(img_fpath)\n",
        "    height = img.size[1]\n",
        "    width = img.size[0]\n",
        "    filename = str.encode(example.id)\n",
        "    with open(img_fpath, mode='rb') as f:\n",
        "        encoded_image_data = f.read()\n",
        "    image_format = b'jpeg'\n",
        "\n",
        "    # List of normalized left x coordinates in bounding box (1 per box)\n",
        "    xmins = [example.xmin1 / float(width), example.xmin2 / float(width)] \n",
        "    # List of normalized right x coordinates in bounding box # (1 per box)\n",
        "    xmaxs = [example.xmax1 / float(width), example.xmax2 / float(width)] \n",
        "    # List of normalized top y coordinates in bounding box (1 per box)\n",
        "    ymins = [example.ymin1 / float(height), example.ymin2 / float(height)] \n",
        "    # List of normalized bottom y coordinates in bounding box # (1 per box)\n",
        "    ymaxs = [example.ymax1 / float(height), example.ymax2 / float(height)] \n",
        "    # List of string class name of bounding box (1 per box)\n",
        "    classes_text = [b'Dog', b'Stump']\n",
        "    # List of integer class id of bounding box (1 per box)\n",
        "    classes = [2]\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow1NNywGecQ2"
      },
      "source": [
        "### Чтение CSV файла с разметкой\n",
        "В данном файле представлена разметка обучающих изображений. Сам файл и его формат показаны лишь для примера, они никак не связаны с библиотекой `object_detection`. Наша финальная цель -- создать датасет в формате `TFRecord`, состоящий из экземпляров `tf.train.Example`.\n",
        "\n",
        "---\n",
        "\n",
        "В данном примере формат файла annot.csv следующий (один бокс на файл):\n",
        "\n",
        "id,xmin,ymin,xmax,ymax\n",
        "\n",
        "1.jpg,261,260,601,615\n",
        "\n",
        "2.jpg,130,429,401,734\n",
        "\n",
        "...\n",
        "\n",
        "---\n",
        "\n",
        "Перед запуском этого блока загрузите необходимые данные (папка `my_data`) в текущую рабочую директорию (tf_od_demo). Один из вариантов, как это можно сделать, это загрузить архив `my_data.7z`, а затем разархивировать его с помощью команды:\n",
        "\n",
        "`!7z x my_data.7z`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8alLq1uilZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9440000-5506-48d4-b804-5f05092a2115"
      },
      "source": [
        "if True:\n",
        "  !7z x my_data2.7z"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 434406 bytes (425 KiB)\n",
            "\n",
            "Extracting archive: my_data2.7z\n",
            "--\n",
            "Path = my_data2.7z\n",
            "Type = 7z\n",
            "Physical Size = 434406\n",
            "Headers Size = 521\n",
            "Method = LZMA2:19\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  0% 9 - my_data2/2.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                       \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 1\n",
            "Files: 20\n",
            "Size:       452216\n",
            "Compressed: 434406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpwJXq1SYy7S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "86b4d04c-f379-49aa-9c30-60f7482871d9"
      },
      "source": [
        "annot = pd.read_csv('my_data2/annot2.csv')\n",
        "annot.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>xmin1</th>\n",
              "      <th>ymin1</th>\n",
              "      <th>xmax1</th>\n",
              "      <th>ymax1</th>\n",
              "      <th>xmin2</th>\n",
              "      <th>ymin2</th>\n",
              "      <th>xmax2</th>\n",
              "      <th>ymax2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>77</td>\n",
              "      <td>272</td>\n",
              "      <td>474</td>\n",
              "      <td>654</td>\n",
              "      <td>463</td>\n",
              "      <td>349</td>\n",
              "      <td>690</td>\n",
              "      <td>602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.jpg</td>\n",
              "      <td>99</td>\n",
              "      <td>308</td>\n",
              "      <td>485</td>\n",
              "      <td>790</td>\n",
              "      <td>483</td>\n",
              "      <td>387</td>\n",
              "      <td>717</td>\n",
              "      <td>686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.jpg</td>\n",
              "      <td>14</td>\n",
              "      <td>305</td>\n",
              "      <td>491</td>\n",
              "      <td>733</td>\n",
              "      <td>483</td>\n",
              "      <td>392</td>\n",
              "      <td>711</td>\n",
              "      <td>673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>25</td>\n",
              "      <td>163</td>\n",
              "      <td>455</td>\n",
              "      <td>681</td>\n",
              "      <td>474</td>\n",
              "      <td>248</td>\n",
              "      <td>711</td>\n",
              "      <td>583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.jpg</td>\n",
              "      <td>14</td>\n",
              "      <td>351</td>\n",
              "      <td>453</td>\n",
              "      <td>768</td>\n",
              "      <td>474</td>\n",
              "      <td>409</td>\n",
              "      <td>706</td>\n",
              "      <td>705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  xmin1  ymin1  xmax1  ymax1  xmin2  ymin2  xmax2  ymax2\n",
              "0  1.jpg     77    272    474    654    463    349    690    602\n",
              "1  2.jpg     99    308    485    790    483    387    717    686\n",
              "2  3.jpg     14    305    491    733    483    392    711    673\n",
              "3  4.jpg     25    163    455    681    474    248    711    583\n",
              "4  5.jpg     14    351    453    768    474    409    706    705"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90HTWYRmhRrP"
      },
      "source": [
        "### Создание TFRecord\n",
        "Здесь мы создаём финальный датасет в формате `TFRecord`, который необходим для запуска обучения TF Object Detection. \n",
        "\n",
        "В цикле по всем обучающим образцам создаем `TF Example` и записываем его в `TF Record`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReFXnPuwZLoB"
      },
      "source": [
        "writer = tf.python_io.TFRecordWriter('my_data2/train_data.record')\n",
        "\n",
        "for idx, row in annot.iterrows():\n",
        "    tf_example = create_tf_example(row)\n",
        "    writer.write(tf_example.SerializeToString())\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bl1CWfDr7QF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}