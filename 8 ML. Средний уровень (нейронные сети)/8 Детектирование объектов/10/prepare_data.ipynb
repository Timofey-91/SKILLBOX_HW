{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10.10_prepare_data (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddfo42JUxiv2"
      },
      "source": [
        "\n",
        "# TensorFlow Object Detection: Подготовка данных для обучения\n",
        "\n",
        "https://github.com/tensorflow/models/tree/master/research/object_detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNXSkTUskE2G"
      },
      "source": [
        "### Монтирование Google Drive\n",
        "Для данного демо нам понадобятся несколько ноутбуков, которые должны работать с одними и теме же данными. Поэтому, чтобы все ноутбуки имели доступ к нужным данным, нам будет необходимо подключить диск Google Drive и сохранять все данные на нём (включая данные, скачанные из интернета).\n",
        "\n",
        "Для монтирования диска нужно выполнить данный блок, перейти по ссылке, получить код, скопировать его в поле ниже (в этом блоке) и нажать Enter\n",
        "\n",
        "После монтирования диск будет находиться здесь: `/content/drive/My Drive`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4GE9oRXhvYX",
        "outputId": "639dde52-a7c3-4dcd-837a-c7afb88f73a5"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwmROL4Bho-r",
        "outputId": "173fe422-4898-4c21-8a2d-7287d032e7e2"
      },
      "source": [
        "pip install tf_slim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\r\u001b[K     |█                               | 10kB 24.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 15.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 14.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 14.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHW9rFr1l8Nk"
      },
      "source": [
        "pip install lvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAsG6Dc8kuQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3426ffb2-d432-4a03-e4cc-4e4cb23ec49a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnnmVH__kx5B"
      },
      "source": [
        "### Рабочая директория\n",
        "Все данные будем хранить в директории `/content/drive/My Drive/tf_od_demo` (TensorFlow Object Detection Demo)\n",
        "\n",
        "При первом запуске создадим директорию (если её еще не существует), в противном случае надо заменить True на False.\n",
        "\n",
        "При последующих подключениях к диску (в том числе в других ноутбуках) директорию создавать не надо, в ней уже будут сохранены все данные, которые мы туда поместили."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khoZUcm6lrbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c30b29a2-cc8e-4445-cdd3-d1b8341aadec"
      },
      "source": [
        "if True:\n",
        "    !mkdir \"/content/drive/My Drive/tf_od_demo\"\n",
        "%cd \"/content/drive/My Drive/tf_od_demo\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/tf_od_demo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk53xwHtalrN"
      },
      "source": [
        "### Подготовка библиотеки `object_detection`\n",
        "Библиотека `object_detection` находится в репозитории `tensorflow/models` в разделе `research`\n",
        "\n",
        "Необходимо склонировать код библиотеки и сконфигурировать модели (сбилдить прото модели).\n",
        "\n",
        "Этот шаг нужно сделать один раз (не повторять, если папка `models` уже находится в текущей директории).\n",
        "\n",
        "Подробнее: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPueN9mCBpHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6509d98-7760-41e6-c1e7-ed6f3f70b82a"
      },
      "source": [
        "if True:\n",
        "  \n",
        "    !git clone https://github.com/tensorflow/models\n",
        "    !cd models/research && protoc object_detection/protos/*.proto --python_out=.\n",
        "    !cd models/research && export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim && python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 47709, done.\u001b[K\n",
            "remote: Total 47709 (delta 0), reused 0 (delta 0), pack-reused 47709\u001b[K\n",
            "Receiving objects: 100% (47709/47709), 551.87 MiB | 20.16 MiB/s, done.\n",
            "Resolving deltas: 100% (32863/32863), done.\n",
            "Checking out files: 100% (2154/2154), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFCMljCEx9VW"
      },
      "source": [
        "### Загрузка библиотек\n",
        "Загрузка TensorFlow и других библиотек. Кроме того, загрузка модуля `dataset_util` из пакета `object_detection`, который будет нужен для создания датасета в нужном формате."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH8kQ2q30B03"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, 'models/research')\n",
        "\n",
        "from object_detection.utils import dataset_util"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZmalcqDcwWG"
      },
      "source": [
        "### Функция для создания одного обучающего образца\n",
        "В этой функции создаётся экземпляр класса `tf.train.Example`, который соответствует одной обучающей картике. Ей могут соответствовать несколько ground-truth баундинг боксов. Однако, конкретно в данном примере на картинке есть строго один бокс. В противном случае списки `xmins`, `xmaxs`, `ymins`, `ymaxs`, `classes_text`, `classes` должны иметь соответствующее количество элементов ( = кол-ву боксов на данной картинке).\n",
        "\n",
        "Создавать экземпляры класса `tf.train.Example` можно произвольным способом. В данном примере на вход в функцию подаётся строка из CSV файла (`annot.csv`). Главное -- заполнить соовтестсвующие поля словаре `feature={...}`\n",
        "\n",
        "Подробнее: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvz1hSw70OyQ"
      },
      "source": [
        "def create_tf_example(example):\n",
        "  \n",
        "    img_fpath = os.path.join('my_data', example.id)\n",
        "    img = Image.open(img_fpath)\n",
        "    height = img.size[1]\n",
        "    width = img.size[0]\n",
        "    filename = str.encode(example.id)\n",
        "    with open(img_fpath, mode='rb') as f:\n",
        "        encoded_image_data = f.read()\n",
        "    image_format = b'jpeg'\n",
        "\n",
        "    # List of normalized left x coordinates in bounding box (1 per box)\n",
        "    xmins = [example.xmin / float(width)] \n",
        "    # List of normalized right x coordinates in bounding box # (1 per box)\n",
        "    xmaxs = [example.xmax / float(width)] \n",
        "    # List of normalized top y coordinates in bounding box (1 per box)\n",
        "    ymins = [example.ymin / float(height)] \n",
        "    # List of normalized bottom y coordinates in bounding box # (1 per box)\n",
        "    ymaxs = [example.ymax / float(height)] \n",
        "    # List of string class name of bounding box (1 per box)\n",
        "    classes_text = [b'Cube']\n",
        "    # List of integer class id of bounding box (1 per box)\n",
        "    classes = [1]\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow1NNywGecQ2"
      },
      "source": [
        "### Чтение CSV файла с разметкой\n",
        "В данном файле представлена разметка обучающих изображений. Сам файл и его формат показаны лишь для примера, они никак не связаны с библиотекой `object_detection`. Наша финальная цель -- создать датасет в формате `TFRecord`, состоящий из экземпляров `tf.train.Example`.\n",
        "\n",
        "---\n",
        "\n",
        "В данном примере формат файла annot.csv следующий (один бокс на файл):\n",
        "\n",
        "id,xmin,ymin,xmax,ymax\n",
        "\n",
        "1.jpg,261,260,601,615\n",
        "\n",
        "2.jpg,130,429,401,734\n",
        "\n",
        "...\n",
        "\n",
        "---\n",
        "\n",
        "Перед запуском этого блока загрузите необходимые данные (папка `my_data`) в текущую рабочую директорию (tf_od_demo). Один из вариантов, как это можно сделать, это загрузить архив `my_data.7z`, а затем разархивировать его с помощью команды:\n",
        "\n",
        "`!7z x my_data.7z`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8alLq1uilZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a97b32-9488-4881-b4cf-b7b53c335d4e"
      },
      "source": [
        "if True:\n",
        "    !7z x my_data.7z"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 1729791 bytes (1690 KiB)\n",
            "\n",
            "Extracting archive: my_data.7z\n",
            "--\n",
            "Path = my_data.7z\n",
            "Type = 7z\n",
            "Physical Size = 1729791\n",
            "Headers Size = 375\n",
            "Method = LZMA2:21\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b 60% 3 - my_data/3.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 1\n",
            "Files: 13\n",
            "Size:       1745448\n",
            "Compressed: 1729791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpwJXq1SYy7S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "41277201-2184-4d40-c1fd-e12ffae61e96"
      },
      "source": [
        "annot = pd.read_csv('my_data/annot.csv')\n",
        "annot.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>261</td>\n",
              "      <td>260</td>\n",
              "      <td>601</td>\n",
              "      <td>615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.jpg</td>\n",
              "      <td>130</td>\n",
              "      <td>429</td>\n",
              "      <td>401</td>\n",
              "      <td>734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.jpg</td>\n",
              "      <td>254</td>\n",
              "      <td>367</td>\n",
              "      <td>527</td>\n",
              "      <td>672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>238</td>\n",
              "      <td>348</td>\n",
              "      <td>537</td>\n",
              "      <td>681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.jpg</td>\n",
              "      <td>244</td>\n",
              "      <td>438</td>\n",
              "      <td>524</td>\n",
              "      <td>766</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  xmin  ymin  xmax  ymax\n",
              "0  1.jpg   261   260   601   615\n",
              "1  2.jpg   130   429   401   734\n",
              "2  3.jpg   254   367   527   672\n",
              "3  4.jpg   238   348   537   681\n",
              "4  5.jpg   244   438   524   766"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90HTWYRmhRrP"
      },
      "source": [
        "### Создание TFRecord\n",
        "Здесь мы создаём финальный датасет в формате `TFRecord`, который необходим для запуска обучения TF Object Detection. \n",
        "\n",
        "В цикле по всем обучающим образцам создаем `TF Example` и записываем его в `TF Record`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReFXnPuwZLoB"
      },
      "source": [
        "writer = tf.python_io.TFRecordWriter('my_data/train_data.record')\n",
        "\n",
        "for idx, row in annot.iterrows():\n",
        "    tf_example = create_tf_example(row)\n",
        "    writer.write(tf_example.SerializeToString())\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bl1CWfDr7QF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}