{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Реализация Encoder-Decoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRT_4fzVVOsQ"
      },
      "source": [
        "# Реализация Encoder-Decoder\n",
        "\n",
        "В этом уроке мы рассмотрим реализацию модели Seq2Seq (Encoder-Decoder) на практике. Реализуем модель саостоятельно с помощью TensorFlow (из готовых модулей будем использовать только LSTM слои) и обучим её на простой задаче машинного перевода с английского на русский."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8biC-GtOVyxz"
      },
      "source": [
        "### Используем TensorFlow 2.0\n",
        "\n",
        "На момент подготовки этих материалов в Google Colab по умолчанию используется версия TensorFlow 1.X\n",
        "\n",
        "Переключаемся на версию 2.0 (работает только в Colab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMnq-IQdUYef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bebce345-fa28-4646-c5cb-52b425f7c288"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKuBDSzEV1wL"
      },
      "source": [
        "### Загрузка библиотек\n",
        "TensorFlow должен иметь как минимум версию 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ew7HTbPpCJH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91b5c5bc-96cf-432e-8555-3a348cf073dc"
      },
      "source": [
        "import codecs\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRJ_L-W8V8Ir"
      },
      "source": [
        "### Загрузка датасета\n",
        "\n",
        "В качестве обучающего датасета будем использовать пары коротких английских и русских предложений (источник: http://www.manythings.org/anki/). Возьмём первые 10000 фраз (они отсортированы по длине, так что мы берем самые короткие для простоты).\n",
        "\n",
        "Для работы этого кода необходимо загрузить файл `rus.txt` в Colab.\n",
        "\n",
        "Считываем строчки из этого файла, парсим их и помещаем предложения в списки `input_texts` и `target_texts` (входные и выходные предложения соответственно)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhhGVySjoFU5"
      },
      "source": [
        "data_fpath = '/content/rus.txt'\n",
        "max_sentences = 10000\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "lines = codecs.open(data_fpath, 'r', encoding='utf8').readlines()[:max_sentences]\n",
        "for line in lines:\n",
        "    input_text, target_text, = line.split('\\t')[:2]\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVXrRV2PW4Lf"
      },
      "source": [
        "### Подготовка словарей\n",
        "\n",
        "Как и раньше, в качестве элемента последовательности будем использовать один символ (а не слово). Это подойдет для нашей простой задачи с короткими предложениями.\n",
        "\n",
        "Подготовим два словаря (отображения индекса в символ и символа в индекс), и сделаем это для входных текстов (`input_texts`) и выходных (`target_texts`), так как они на разных языках и состоят из разных символов.\n",
        "\n",
        "Кроме того, нам понадобятся специальные токены для начала и конца цепочки (`<START>`, `<END>`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdTllVeCrQuI"
      },
      "source": [
        "def prepare_vocab(texts):\n",
        "    vocab = sorted(set(''.join(texts)))\n",
        "    vocab.append('<START>')\n",
        "    vocab.append('<END>')\n",
        "    vocab_size = len(vocab)\n",
        "    char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "    idx2char = np.array(vocab)\n",
        "    return vocab_size, char2idx, idx2char\n",
        "\n",
        "INPUT_VOCAB_SIZE, input_char2idx, input_idx2char = prepare_vocab(input_texts)\n",
        "TARGET_VOCAB_SIZE, target_char2idx, target_idx2char = prepare_vocab(target_texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dvz4PBoYKSy"
      },
      "source": [
        "### Подготовка обучающего датасета\n",
        "\n",
        "Наша модель будет состоять из двух частей: `Encoder` и `Decoder`. Задача энкодера считать входную цепочку и получить её закодированное представление. А задача декодера по этому закодированному представлению получить выходную цепочку.\n",
        "\n",
        "Декодер по сути является генератором текста, поэтому используется он аналогично тому, как мы это делали ранее с символьным генератором текста. Отличие только в том, что тут декодер будет получать начальное состояние из энкодера, а в качестве \"начала\" цепочки будет получать токен `<START>`.\n",
        "\n",
        "И точно так же, как и в случае с генератором, для обучения декодера в качестве входа и целевого выхода будем использовать одну и ту же цепочку, но сдвинутую на один элемент во времени. В конце Декодер должен предсказать токен `<END>`.\n",
        "\n",
        "Например, входом и выходом для декодера могут быть такие две цепочки из семи символов (начальный и конечный токен это один символ):\n",
        "\n",
        "`<START>Привет` --> `Привет<END>`\n",
        "\n",
        "Таким образом, для обучения `Encoder-Decoder` нам понадоятся три набора цепочек:\n",
        " - `encoder_input_seqs` - входы в Encoder\n",
        " - `decoder_input_seqs` - входы в Decoder\n",
        " - `decoder_target_seqs` - целевые выходы из Decoder (и всей модели Encoder-Decoder)\n",
        "\n",
        "Сами цепочки будут являться последовательностями целочисленных индексов (полученных с помощью соответствующих словарей).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptvZBL0DrjSA"
      },
      "source": [
        "input_texts_as_int = [[input_char2idx[c] for c in text] for text in input_texts]\n",
        "target_texts_as_int = [[target_char2idx[c] for c in text] for text in target_texts]\n",
        "\n",
        "encoder_input_seqs = [np.array(text) for text in input_texts_as_int]\n",
        "decoder_input_seqs = []\n",
        "decoder_target_seqs = []\n",
        "for target_text in target_texts_as_int:\n",
        "    decoder_input_seqs.append(np.array([target_char2idx['<START>']] + target_text))\n",
        "    decoder_target_seqs.append(np.array(target_text + [target_char2idx['<END>']]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee7NkLh-a9Cc"
      },
      "source": [
        "### Паддинг цепочек\n",
        "\n",
        "Вспомним, что для обучения нам надо использовать батчи, которые состоят из цепочек одинаковой длины. А изначально длина цепочек (как входных, так и выходных) может быть произвольной. Поэтому нам необходимо сделать паддинг -- дополнить все цепочки до некоторой фиксированной длины. Например, с помощью символа пробела `' '`. В качестве длин будем брать максимально возможные среди всех имеющихся цепочек (отдельно для входных, отдельно для выходных)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMk-6fNdx5Ff"
      },
      "source": [
        "max_enc_seq_length = max([len(seq) for seq in encoder_input_seqs])\n",
        "max_dec_seq_length = max([len(seq) for seq in decoder_input_seqs])\n",
        "\n",
        "encoder_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    encoder_input_seqs,\n",
        "    value=input_char2idx[' '],\n",
        "    padding='post',\n",
        "    maxlen=max_enc_seq_length)\n",
        "\n",
        "decoder_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    decoder_input_seqs,\n",
        "    value=target_char2idx[' '],\n",
        "    padding='post',\n",
        "    maxlen=max_dec_seq_length)\n",
        "\n",
        "decoder_target_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    decoder_target_seqs,\n",
        "    value=target_char2idx[' '],\n",
        "    padding='post',\n",
        "    maxlen=max_dec_seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY-yw6zNcWdK"
      },
      "source": [
        "### Создание модели\n",
        "\n",
        "Для создания Encoder-Decoder модели воспользуемся смесьюдвух стилей: реализация моеделй через собственный класс и функциональный API. \n",
        "\n",
        "Сами по себе Encoder и Decoder (по отдельности) удобно реализовать в виде кастомных классов (наследованных от `tf.keras.Model`), так как у них может быть какая-то сложная реализация. \n",
        "\n",
        "В нашем случае Encoder будет состоять из Embedding слоя и одного LSTM слоя, который будет возвращать финальное состояние после прохода по всей цепочке. В качестве состояния нас интересует и вектор `h` и вектор состояния LSTM `c`. Для него нам понадобится дополнительный флаг `return_state=True`\n",
        "\n",
        "В Декодере будет Embedding, LSTM и полносвязный слой для генерации финальных ответов (распределение вероятностей по символам). Для прямого распространения (`__call__`) кроме входной цепочки декодер будет получать состояние от энкодера (`init_state`) и будет передавать его в свой LSTM слоя в качестве начального состояния, а возвращать будет предсказанную выходную цепочку (той же длины, return_sequences=True) состояние этого LSTM.\n",
        "\n",
        "После того, как мы отдельно построили Encoder и Decoder, надо соединить их в Encoder-Decoder. Но так как нам нужно создать несколько входов в модель (отдельно входная цепочка в энкодер, отдельно входная цепочка в декодер) очень удобно сделать это с помощью функционального API. Фходные узлы создаются с помощью `tf.keras.layers.Input`, а затем строим вычислительный граф, используя модели `encoder_model` и `decoder_model`.\n",
        "\n",
        "Финальная модель -- `seq2seq`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxaSL4NGfdOC"
      },
      "source": [
        "H_SIZE = 256 # Размерность скрытого состояния LSTM\n",
        "EMB_SIZE = 256 # размерность эмбеддингов (и для входных и для выходных цепочек)\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(INPUT_VOCAB_SIZE, EMB_SIZE)\n",
        "        self.lstm = tf.keras.layers.LSTM(H_SIZE, return_sequences=False, return_state=True)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embed(x)\n",
        "        _, h, c = self.lstm(out)\n",
        "        state = (h, c)\n",
        "        return state\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(TARGET_VOCAB_SIZE, EMB_SIZE)\n",
        "        self.lstm = tf.keras.layers.LSTM(H_SIZE, return_sequences=True, return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(TARGET_VOCAB_SIZE, activation='softmax')\n",
        "        \n",
        "    def call(self, x, init_state):\n",
        "        out = self.embed(x)\n",
        "        out, h, c = self.lstm(out, initial_state=init_state)\n",
        "        out = self.fc(out)\n",
        "        state = (h, c)\n",
        "        return out, state\n",
        "\n",
        "encoder_model = Encoder()\n",
        "decoder_model = Decoder()\n",
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "enc_state = encoder_model(encoder_inputs)\n",
        "decoder_outputs, _ = decoder_model(decoder_inputs, enc_state)\n",
        "\n",
        "seq2seq = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FQX_z5Kcacx"
      },
      "source": [
        "### Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rT1D_MQYxKm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "795a1116-ed9b-43dc-c710-3c7682ee354c"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "\n",
        "loss = tf.losses.SparseCategoricalCrossentropy()\n",
        "seq2seq.compile(optimizer='rmsprop', loss=loss, metrics=['accuracy'])\n",
        "seq2seq.fit([encoder_input_seqs, decoder_input_seqs], decoder_target_seqs,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples\n",
            "Epoch 1/100\n",
            "10000/10000 [==============================] - 11s 1ms/sample - loss: 0.8402 - accuracy: 0.7942\n",
            "Epoch 2/100\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.5379 - accuracy: 0.8448\n",
            "Epoch 3/100\n",
            "10000/10000 [==============================] - 3s 304us/sample - loss: 0.4682 - accuracy: 0.8628\n",
            "Epoch 4/100\n",
            "10000/10000 [==============================] - 3s 309us/sample - loss: 0.4199 - accuracy: 0.8772\n",
            "Epoch 5/100\n",
            "10000/10000 [==============================] - 3s 303us/sample - loss: 0.3839 - accuracy: 0.8875\n",
            "Epoch 6/100\n",
            "10000/10000 [==============================] - 3s 305us/sample - loss: 0.3551 - accuracy: 0.8960\n",
            "Epoch 7/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.3306 - accuracy: 0.9031\n",
            "Epoch 8/100\n",
            "10000/10000 [==============================] - 3s 307us/sample - loss: 0.3096 - accuracy: 0.9090\n",
            "Epoch 9/100\n",
            "10000/10000 [==============================] - 3s 303us/sample - loss: 0.2915 - accuracy: 0.9143\n",
            "Epoch 10/100\n",
            "10000/10000 [==============================] - 3s 299us/sample - loss: 0.2750 - accuracy: 0.9191\n",
            "Epoch 11/100\n",
            "10000/10000 [==============================] - 3s 303us/sample - loss: 0.2599 - accuracy: 0.9232\n",
            "Epoch 12/100\n",
            "10000/10000 [==============================] - 3s 309us/sample - loss: 0.2464 - accuracy: 0.9271\n",
            "Epoch 13/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.2337 - accuracy: 0.9307\n",
            "Epoch 14/100\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.2221 - accuracy: 0.9342\n",
            "Epoch 15/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.2113 - accuracy: 0.9373\n",
            "Epoch 16/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.2010 - accuracy: 0.9403\n",
            "Epoch 17/100\n",
            "10000/10000 [==============================] - 3s 298us/sample - loss: 0.1912 - accuracy: 0.9433\n",
            "Epoch 18/100\n",
            "10000/10000 [==============================] - 3s 303us/sample - loss: 0.1821 - accuracy: 0.9458\n",
            "Epoch 19/100\n",
            "10000/10000 [==============================] - 3s 304us/sample - loss: 0.1734 - accuracy: 0.9482\n",
            "Epoch 20/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.1653 - accuracy: 0.9509\n",
            "Epoch 21/100\n",
            "10000/10000 [==============================] - 3s 305us/sample - loss: 0.1576 - accuracy: 0.9530\n",
            "Epoch 22/100\n",
            "10000/10000 [==============================] - 3s 303us/sample - loss: 0.1500 - accuracy: 0.9553\n",
            "Epoch 23/100\n",
            "10000/10000 [==============================] - 3s 303us/sample - loss: 0.1432 - accuracy: 0.9572\n",
            "Epoch 24/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.1367 - accuracy: 0.9592\n",
            "Epoch 25/100\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.1304 - accuracy: 0.9608\n",
            "Epoch 26/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.1243 - accuracy: 0.9628\n",
            "Epoch 27/100\n",
            "10000/10000 [==============================] - 3s 305us/sample - loss: 0.1187 - accuracy: 0.9644\n",
            "Epoch 28/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.1136 - accuracy: 0.9658\n",
            "Epoch 29/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.1082 - accuracy: 0.9670\n",
            "Epoch 30/100\n",
            "10000/10000 [==============================] - 3s 303us/sample - loss: 0.1036 - accuracy: 0.9686\n",
            "Epoch 31/100\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.0994 - accuracy: 0.9699\n",
            "Epoch 32/100\n",
            "10000/10000 [==============================] - 3s 299us/sample - loss: 0.0952 - accuracy: 0.9710\n",
            "Epoch 33/100\n",
            "10000/10000 [==============================] - 3s 308us/sample - loss: 0.0908 - accuracy: 0.9722\n",
            "Epoch 34/100\n",
            "10000/10000 [==============================] - 3s 299us/sample - loss: 0.0873 - accuracy: 0.9732\n",
            "Epoch 35/100\n",
            "10000/10000 [==============================] - 3s 299us/sample - loss: 0.0838 - accuracy: 0.9742\n",
            "Epoch 36/100\n",
            "10000/10000 [==============================] - 3s 298us/sample - loss: 0.0803 - accuracy: 0.9752\n",
            "Epoch 37/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0771 - accuracy: 0.9761\n",
            "Epoch 38/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.0742 - accuracy: 0.9768\n",
            "Epoch 39/100\n",
            "10000/10000 [==============================] - 3s 298us/sample - loss: 0.0712 - accuracy: 0.9777\n",
            "Epoch 40/100\n",
            "10000/10000 [==============================] - 3s 305us/sample - loss: 0.0687 - accuracy: 0.9785\n",
            "Epoch 41/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0661 - accuracy: 0.9791\n",
            "Epoch 42/100\n",
            "10000/10000 [==============================] - 3s 298us/sample - loss: 0.0638 - accuracy: 0.9796\n",
            "Epoch 43/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.0616 - accuracy: 0.9802\n",
            "Epoch 44/100\n",
            "10000/10000 [==============================] - 3s 305us/sample - loss: 0.0596 - accuracy: 0.9810\n",
            "Epoch 45/100\n",
            "10000/10000 [==============================] - 3s 298us/sample - loss: 0.0576 - accuracy: 0.9813\n",
            "Epoch 46/100\n",
            "10000/10000 [==============================] - 3s 298us/sample - loss: 0.0558 - accuracy: 0.9817\n",
            "Epoch 47/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0541 - accuracy: 0.9822\n",
            "Epoch 48/100\n",
            "10000/10000 [==============================] - 3s 299us/sample - loss: 0.0526 - accuracy: 0.9827\n",
            "Epoch 49/100\n",
            "10000/10000 [==============================] - 3s 304us/sample - loss: 0.0512 - accuracy: 0.9830\n",
            "Epoch 50/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0497 - accuracy: 0.9833\n",
            "Epoch 51/100\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.0484 - accuracy: 0.9837\n",
            "Epoch 52/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.0471 - accuracy: 0.9839\n",
            "Epoch 53/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0461 - accuracy: 0.9844\n",
            "Epoch 54/100\n",
            "10000/10000 [==============================] - 3s 299us/sample - loss: 0.0451 - accuracy: 0.9845\n",
            "Epoch 55/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0441 - accuracy: 0.9848\n",
            "Epoch 56/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0432 - accuracy: 0.9849\n",
            "Epoch 57/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0421 - accuracy: 0.9851\n",
            "Epoch 58/100\n",
            "10000/10000 [==============================] - 3s 304us/sample - loss: 0.0416 - accuracy: 0.9853\n",
            "Epoch 59/100\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.0408 - accuracy: 0.9855\n",
            "Epoch 60/100\n",
            "10000/10000 [==============================] - 3s 299us/sample - loss: 0.0401 - accuracy: 0.9857\n",
            "Epoch 61/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0395 - accuracy: 0.9858\n",
            "Epoch 62/100\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.0389 - accuracy: 0.9859\n",
            "Epoch 63/100\n",
            "10000/10000 [==============================] - 3s 298us/sample - loss: 0.0383 - accuracy: 0.9861\n",
            "Epoch 64/100\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.0379 - accuracy: 0.9860\n",
            "Epoch 65/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.0373 - accuracy: 0.9862\n",
            "Epoch 66/100\n",
            "10000/10000 [==============================] - 3s 296us/sample - loss: 0.0368 - accuracy: 0.9864\n",
            "Epoch 67/100\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.0365 - accuracy: 0.9865\n",
            "Epoch 68/100\n",
            "10000/10000 [==============================] - 3s 304us/sample - loss: 0.0360 - accuracy: 0.9865\n",
            "Epoch 69/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.0355 - accuracy: 0.9867\n",
            "Epoch 70/100\n",
            "10000/10000 [==============================] - 3s 299us/sample - loss: 0.0355 - accuracy: 0.9865\n",
            "Epoch 71/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0349 - accuracy: 0.9867\n",
            "Epoch 72/100\n",
            "10000/10000 [==============================] - 3s 303us/sample - loss: 0.0348 - accuracy: 0.9868\n",
            "Epoch 73/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0343 - accuracy: 0.9867\n",
            "Epoch 74/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.0340 - accuracy: 0.9869\n",
            "Epoch 75/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.0336 - accuracy: 0.9869\n",
            "Epoch 76/100\n",
            "10000/10000 [==============================] - 3s 299us/sample - loss: 0.0335 - accuracy: 0.9869\n",
            "Epoch 77/100\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.0333 - accuracy: 0.9870\n",
            "Epoch 78/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0330 - accuracy: 0.9868\n",
            "Epoch 79/100\n",
            "10000/10000 [==============================] - 3s 304us/sample - loss: 0.0327 - accuracy: 0.9870\n",
            "Epoch 80/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.0325 - accuracy: 0.9871\n",
            "Epoch 81/100\n",
            "10000/10000 [==============================] - 3s 308us/sample - loss: 0.0322 - accuracy: 0.9871\n",
            "Epoch 82/100\n",
            "10000/10000 [==============================] - 3s 309us/sample - loss: 0.0321 - accuracy: 0.9871\n",
            "Epoch 83/100\n",
            "10000/10000 [==============================] - 3s 312us/sample - loss: 0.0320 - accuracy: 0.9871\n",
            "Epoch 84/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0317 - accuracy: 0.9873\n",
            "Epoch 85/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0316 - accuracy: 0.9872\n",
            "Epoch 86/100\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.0316 - accuracy: 0.9871\n",
            "Epoch 87/100\n",
            "10000/10000 [==============================] - 3s 297us/sample - loss: 0.0310 - accuracy: 0.9872\n",
            "Epoch 88/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.0310 - accuracy: 0.9872\n",
            "Epoch 89/100\n",
            "10000/10000 [==============================] - 3s 304us/sample - loss: 0.0310 - accuracy: 0.9873\n",
            "Epoch 90/100\n",
            "10000/10000 [==============================] - 3s 299us/sample - loss: 0.0308 - accuracy: 0.9873\n",
            "Epoch 91/100\n",
            "10000/10000 [==============================] - 3s 300us/sample - loss: 0.0308 - accuracy: 0.9871\n",
            "Epoch 92/100\n",
            "10000/10000 [==============================] - 3s 299us/sample - loss: 0.0306 - accuracy: 0.9872\n",
            "Epoch 93/100\n",
            "10000/10000 [==============================] - 3s 304us/sample - loss: 0.0303 - accuracy: 0.9872\n",
            "Epoch 94/100\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.0301 - accuracy: 0.9873\n",
            "Epoch 95/100\n",
            "10000/10000 [==============================] - 3s 298us/sample - loss: 0.0302 - accuracy: 0.9872\n",
            "Epoch 96/100\n",
            "10000/10000 [==============================] - 3s 302us/sample - loss: 0.0300 - accuracy: 0.9873\n",
            "Epoch 97/100\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.0297 - accuracy: 0.9873\n",
            "Epoch 98/100\n",
            "10000/10000 [==============================] - 3s 299us/sample - loss: 0.0297 - accuracy: 0.9873\n",
            "Epoch 99/100\n",
            "10000/10000 [==============================] - 3s 307us/sample - loss: 0.0296 - accuracy: 0.9873\n",
            "Epoch 100/100\n",
            "10000/10000 [==============================] - 3s 301us/sample - loss: 0.0296 - accuracy: 0.9873\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f55ce215fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5M_8rngc137"
      },
      "source": [
        "### Функция для инференса\n",
        "\n",
        "Запуск инференса для Encoder-Decoder состоит из последовательного применения энкодера и декодера. \n",
        "\n",
        "Сначала прогоняем входную цепочку через энкодер и получаем закодированное представление `state`.\n",
        "\n",
        "А дальше применяем декодер в похожем режиме, как это было с генератором текста (только теперь передаём `state` в качестве начального состояния). В цикле постепенно генерируем выходную цепочку, подавая в декодер лишь один (текущий) символ и получая один предсказанный (следующий) символ. Начинаем с символа `<START>` и повторяем до тех пор, пока не получим символ `<END>` на выходе или не достигнем лимита по количеству символов в цепочке. Для определения того, какой символ предсказал декодер, просто воспользуемся  функцией `argmax` для выходного распределения (выхода FC слоя)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-jCrL-_ad2V"
      },
      "source": [
        "def seq2seq_inference(input_seq):\n",
        "    state = encoder_model(input_seq)\n",
        "\n",
        "    target_seq = np.array([[target_char2idx['<START>']]])\n",
        "\n",
        "    decoded_sentence = ''\n",
        "    while True:\n",
        "        output_tokens, state = decoder_model(target_seq, state)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = target_idx2char[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '<END>' or\n",
        "           len(decoded_sentence) > max_dec_seq_length):\n",
        "            break\n",
        "\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtUejpB6c6Hx"
      },
      "source": [
        "### Пример инференса\n",
        "\n",
        "Попробуем инференс Seq2Seq моедли на цепочках из нашего датасета."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdTwSl_gaf9o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4387faa6-27df-4d1e-9246-9f332974746d"
      },
      "source": [
        "for seq_index in range(0, 20):\n",
        "    input_seq = encoder_input_seqs[seq_index: seq_index + 1]\n",
        "    decoded_sentence = seq2seq_inference(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Result sentence:', decoded_sentence)\n",
        "    print('Target sentence:', target_texts[seq_index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: Go.\n",
            "Result sentence: Иди.<END\n",
            "Target sentence: Марш!\n",
            "-\n",
            "Input sentence: Go.\n",
            "Result sentence: Иди.<END\n",
            "Target sentence: Иди.\n",
            "-\n",
            "Input sentence: Go.\n",
            "Result sentence: Иди.<END\n",
            "Target sentence: Идите.\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Result sentence: Здрасте.<END\n",
            "Target sentence: Здравствуйте.\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Result sentence: Здрасте.<END\n",
            "Target sentence: Привет!\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Result sentence: Здрасте.<END\n",
            "Target sentence: Хай.\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Result sentence: Здрасте.<END\n",
            "Target sentence: Здрасте.\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Result sentence: Здрасте.<END\n",
            "Target sentence: Здоро́во!\n",
            "-\n",
            "Input sentence: Run!\n",
            "Result sentence: Бегите!<END\n",
            "Target sentence: Беги!\n",
            "-\n",
            "Input sentence: Run!\n",
            "Result sentence: Бегите!<END\n",
            "Target sentence: Бегите!\n",
            "-\n",
            "Input sentence: Run.\n",
            "Result sentence: Бегите!<END\n",
            "Target sentence: Беги!\n",
            "-\n",
            "Input sentence: Run.\n",
            "Result sentence: Бегите!<END\n",
            "Target sentence: Бегите!\n",
            "-\n",
            "Input sentence: Who?\n",
            "Result sentence: Кто?<END\n",
            "Target sentence: Кто?\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Result sentence: Здорово!<END\n",
            "Target sentence: Вот это да!\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Result sentence: Здорово!<END\n",
            "Target sentence: Круто!\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Result sentence: Здорово!<END\n",
            "Target sentence: Здорово!\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Result sentence: Здорово!<END\n",
            "Target sentence: Ух ты!\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Result sentence: Здорово!<END\n",
            "Target sentence: Ого!\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Result sentence: Здорово!<END\n",
            "Target sentence: Вах!\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Result sentence: Огонь!<END\n",
            "Target sentence: Огонь!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFAqqM6FeE5t"
      },
      "source": [
        "**[Задание 1]** Добавьте в модель Encoder-Decoder еще один LSTM слой (для увеличения глубины). Сделать это нужно и в Encoder и в Decoder. Скрытое состояние Энкодера необходимо сохранять для **каждого** LSTM слоя и передавать в соответствющий LSTM слой Декодера (из первого в первый, из второго во второй).\n",
        "\n",
        "**[Задание 2]** Сделайте Encoder в Seq2Seq модели двунаправленным (Bidirectional).\n",
        "\n"
      ]
    }
  ]
}