{"cells": [{"outputs": [], "metadata": {"_uuid": "d9840b2e1759a260028ea9817495ea4230112070", "_cell_guid": "bbb64692-1776-49e2-9f88-a0adcb1bfe6e"}, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "import keras\n", "import json\n", "from datetime import datetime\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "execution_count": 1}, {"outputs": [], "metadata": {"_uuid": "1b76f6850fdd8c9a7d31c1f63d867cc79d089332", "_cell_guid": "1d97515f-0ba9-4c18-9aa9-9baa62ce9cb6"}, "cell_type": "code", "source": ["keras.__version__"], "execution_count": 2}, {"outputs": [], "metadata": {"_uuid": "ec5a680864d004a880cea668fbee628cf689b49d", "collapsed": true, "_cell_guid": "0982cfc9-caff-46d9-b4e9-27c2c647c254"}, "cell_type": "code", "source": ["df = pd.read_csv(\"../input/movie_conversations.tsv\", encoding='utf-8-sig', sep=\"\\t\")"], "execution_count": 3}, {"outputs": [], "metadata": {"_uuid": "b6b6bed154d9ca8b75a4c7b3f392d731cd88a18e", "_cell_guid": "444da42f-b130-453b-8d95-224cdb67dabe"}, "cell_type": "code", "source": ["df.head()"], "execution_count": 4}, {"outputs": [], "metadata": {"_uuid": "78045022106636082cbf3751c8a5be8368c7fd36", "collapsed": true, "_cell_guid": "01604a46-6c44-4d43-904f-e8df670bfb12"}, "cell_type": "code", "source": ["df = pd.read_csv(\"../input/movie_lines.tsv\", encoding='utf-8-sig',header = None)"], "execution_count": 5}, {"outputs": [], "metadata": {"_uuid": "ade4d29aa6f0508d78fd33fa94bdd02f4bde1289", "collapsed": true, "_cell_guid": "ea7d57d4-4bab-4f53-b8db-4658ea20f095"}, "cell_type": "code", "source": ["lines = df[0].str.split('\\t')"], "execution_count": 6}, {"outputs": [], "metadata": {"_uuid": "faaded47b9573e0086323b5b37d759b4342dffb3", "_cell_guid": "cce5dea3-b0b0-46e5-9e50-7159e4d8498b"}, "cell_type": "code", "source": ["dialogue_lines = list()\n", "for x in lines:\n", "    dialogue_lines.append(x[4])\n", "dialogue_lines[:10]"], "execution_count": 7}, {"outputs": [], "metadata": {"_uuid": "675f1b94698875414420ee4ed32cfd32e721fc25", "_cell_guid": "86f945e6-dfbc-4966-a7e2-19f66a33e4f0"}, "cell_type": "code", "source": ["dialogues_path = \"../input/movie_lines.tsv\"\n", "VOCAB_SIZE = 5000 # len(keras_tokenizer.word_index) + 1\n", "print(VOCAB_SIZE)\n", "EMBEDDING_DIM = 500"], "execution_count": 8}, {"outputs": [], "metadata": {"_uuid": "3ac372fbd555fd5099c94bb61089e210305f1047", "_cell_guid": "b6216274-0eab-4bca-803d-68ff736ba0b1"}, "cell_type": "code", "source": ["len(dialogue_lines)"], "execution_count": 9}, {"outputs": [], "metadata": {"_uuid": "08d18cca0ea2c9d0917a1ed682adedebc02abc9a", "collapsed": true, "_cell_guid": "dd9f223c-ac29-4a21-ae28-4fdfd990d0ee"}, "cell_type": "code", "source": ["from keras.preprocessing.text import Tokenizer\n", "from statistics import median\n", "keras_tokenizer = Tokenizer(num_words=VOCAB_SIZE, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}\\t\\n')\n", "keras_tokenizer.fit_on_texts(dialogue_lines)"], "execution_count": 10}, {"outputs": [], "metadata": {"_uuid": "b9b448dbf533997992f8a07d27a262598f1c2ecd", "_cell_guid": "7eca5e2a-8c58-4701-a786-87fd0e278d04"}, "cell_type": "code", "source": ["keras_tokenizer.word_index"], "execution_count": 11}, {"outputs": [], "metadata": {"_uuid": "82b0eda0666af1a6e62d27da0d9e41f0430ea5ab", "collapsed": true, "_cell_guid": "a76378bb-e953-4de7-b558-3476368490ed"}, "cell_type": "code", "source": ["text_sequences = keras_tokenizer.texts_to_sequences(dialogue_lines)[:2000]"], "execution_count": 12}, {"outputs": [], "metadata": {"_uuid": "2f3a07fd0fc1bf0a31bf5a4f8483024d916f0d4e", "_cell_guid": "70bdaa9b-ea2a-498c-aae7-5641f786a774"}, "cell_type": "code", "source": ["MAX_SEQUENCE_LENGTH = int(median(len(sequence) for sequence in text_sequences))\n", "print(MAX_SEQUENCE_LENGTH)"], "execution_count": 13}, {"metadata": {"_uuid": "118bea5df6fc9eccd0561c896165e8c187a19163", "_cell_guid": "14057af8-4b6f-4247-9898-4f49055fefb7"}, "cell_type": "markdown", "source": ["# **Build Neural Network**"]}, {"outputs": [], "metadata": {"_uuid": "e20b40df5d8a6821357a4f8a4cd632767d328e8d", "collapsed": true, "_cell_guid": "629ee8a7-aa7d-40c9-9e3d-a0e69aa43f0c"}, "cell_type": "code", "source": ["from keras import backend as K\n", "from keras.engine.topology import Layer\n", "from keras.layers import Input, Dense, RepeatVector, LSTM, Conv1D, Masking, Embedding\n", "from keras.layers.wrappers import TimeDistributed, Bidirectional\n", "from keras.models import Model\n", "from keras.preprocessing.sequence import pad_sequences"], "execution_count": 14}, {"outputs": [], "metadata": {"_uuid": "ff0e57f9b0bb305c7511178fa54942c3550083b9", "collapsed": true, "_cell_guid": "b633ed01-2bc4-465b-a6ba-5780abd410ce"}, "cell_type": "code", "source": ["x_train = pad_sequences(text_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', \n", "                        truncating='post', value=0)"], "execution_count": 15}, {"outputs": [], "metadata": {"_uuid": "c34e7f46e45065d4ace9b7168cabd7d6ce988be2", "_cell_guid": "ac82cb38-f27b-4ec7-b85a-a7bb4f057520"}, "cell_type": "code", "source": ["x_train.shape"], "execution_count": 16}, {"outputs": [], "metadata": {"_uuid": "7d67dc5c6225fe2b50a7ba4577bf368453b42e64", "collapsed": true, "_cell_guid": "b8014206-6f2b-44f0-bf64-2b549d5ac45d"}, "cell_type": "code", "source": ["x_train_rev = list()\n", "for x_vector in x_train:\n", "    x_rev_vector = list()\n", "    for index in x_vector:\n", "        char_vector = np.zeros(VOCAB_SIZE)\n", "        char_vector[index] = 1\n", "        x_rev_vector.append(char_vector)\n", "    x_train_rev.append(np.asarray(x_rev_vector))\n", "x_train_rev = np.asarray(x_train_rev)\n"], "execution_count": 17}, {"outputs": [], "metadata": {"_uuid": "9ab956752781f17e7a21a27a388f9488ea43ee59", "_cell_guid": "5003dd96-159a-4829-93a1-ad94f618d3e8"}, "cell_type": "code", "source": ["x_train_rev.shape"], "execution_count": 18}, {"outputs": [], "metadata": {"_uuid": "26bce299ab8590bdfb5b84d260d6ddfebadef5d2", "_cell_guid": "1a77da41-1e9d-44ae-8b8e-ae15a99ca035"}, "cell_type": "code", "source": ["def get_seq2seq_model():\n", "    main_input = Input(shape=x_train[0].shape, dtype='float32', name='main_input')\n", "    print(main_input)\n", "\n", "    embed_1 = Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, \n", "                        mask_zero=True, input_length=MAX_SEQUENCE_LENGTH) (main_input)\n", "    print(embed_1)\n", "\n", "    lstm_1 = Bidirectional(LSTM(2048, name='lstm_1'))(embed_1)\n", "    print(lstm_1)\n", "\n", "    repeat_1 = RepeatVector(MAX_SEQUENCE_LENGTH, name='repeat_1')(lstm_1)\n", "    print(repeat_1)\n", "\n", "    lstm_3 = Bidirectional(LSTM(2048, return_sequences=True, name='lstm_3'))(repeat_1)\n", "    print(lstm_3)\n", "\n", "    softmax_1 = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))(lstm_3)\n", "    print(softmax_1)\n", "    \n", "    model = Model(main_input, softmax_1)\n", "    model.compile(optimizer='adam',\n", "                  loss='categorical_crossentropy',\n", "                  metrics=['accuracy'])\n", "    \n", "    return model\n", "seq2seq_model = get_seq2seq_model()\n", "seq2seq_model.fit(x_train, x_train_rev, batch_size=128, epochs=20, verbose=1)\n", "predictions = seq2seq_model.predict(x_train)\n", "index2word_map = inv_map = {v: k for k, v in keras_tokenizer.word_index.items()}"], "execution_count": 19}, {"outputs": [], "metadata": {"_uuid": "8db6fc11ff4eb92cbb74379a566b09dada271834", "collapsed": true, "_cell_guid": "2713fe09-d73f-47b8-bb05-5d98e7908266"}, "cell_type": "code", "source": ["def sequence_to_str(sequence):\n", "    word_list = list()\n", "    for element in sequence:\n", "#         if amax(element) < max_prob:\n", "#             continue\n", "        index = np.argmax(element) + 1\n", "        word = index2word_map[index]\n", "        word_list.append(word)\n", "        \n", "    return word_list"], "execution_count": 20}, {"outputs": [], "metadata": {"_uuid": "8d9a40f451e055bc95f1785a3cb3d8487891d611", "_cell_guid": "2c092c5d-559e-4fc9-aafb-3e1d0db5c21e"}, "cell_type": "code", "source": ["#use_eos=True\n", "for i in range(len(predictions)):\n", "        predicted_word_list = sequence_to_str(predictions[i])\n", "        actual_len = len(dialogue_lines[i])\n", "\n", "        actual_sentence = \"Actual: \" + dialogue_lines[i][:len(dialogue_lines[i])-3]        \n", "        \n", "        generated_sentence = \"\"\n", "        for word in predicted_word_list:\n", "            '''\n", "            if word == EOS_TOKEN:\n", "                predictions_file.write('\\n')\n", "                break\n", "            '''\n", "            generated_sentence += word + \" \"\n", "\n", "        sent_dict = dict()\n", "        sent_dict[\"actual\"] = actual_sentence.strip()\n", "        sent_dict[\"generated\"] = generated_sentence.strip()\n", "        print(sent_dict)"], "execution_count": 23}, {"metadata": {"_uuid": "40a2e2f84b87fe5a50750f4b3c8368eba118d039", "_cell_guid": "4facdfbf-6d05-4c7e-a5e9-32e76b833e1d"}, "cell_type": "markdown", "source": ["**Conclusion:**\n", "That's gibberish and rubbish ;). A lot to change and modify. Seq2Seq is not sufficient to answer these ind of dialogues or we change the architecture and re-train.\n", "\n", "\n", "If it helps you learn something and like it, please upvote and motivate me to write and share more!!"]}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": [], "execution_count": null}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": [], "execution_count": null}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"nbconvert_exporter": "python", "version": "3.6.4", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "name": "python", "file_extension": ".py", "mimetype": "text/x-python"}}, "nbformat": 4, "nbformat_minor": 1}