{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15_dialog_generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40WulyLcjkEW"
      },
      "source": [
        "# Создание чат-бота с использованием модели Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XX2gBOIjnSj"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpw0dLZY5Mkn",
        "outputId": "5a740c32-67a8-42dc-c511-46fc961a955e"
      },
      "source": [
        "# Загрузка библиотек\n",
        "import codecs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot_tJ3-iUBxz"
      },
      "source": [
        "# Загрузка и предварительная обработка данных:\n",
        "\n",
        "* Следующим шагом является переформатирование нашего файла данных и загрузка данных в структуры, с которыми мы можем работать.\n",
        "* Набор данных \"Cornell Movie-Dialogs Corpus\" состоит из следующего описания:\n",
        " * 220 579 разговоров между 10 292 парами героев фильмов\n",
        " * 9035 персонажей из 617 фильмов\n",
        " * 304,713 всего высказываний\n",
        " * Этот набор данных большой и разнообразный, и существует большое разнообразие языковых формальностей, периодов времени, настроений и т. д.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAyvtzg0fysR",
        "outputId": "5f6d2afc-46eb-4543-9f4d-db5525390ba5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSXsxtuE0Dpr",
        "outputId": "8861f3c9-fa68-4ba8-a5e7-59815c714866"
      },
      "source": [
        "movie_convers = open('./drive/My Drive/ChatBot_Dataset/movie_conversations.txt',mode='rt')\n",
        "movie_convers = movie_convers.readlines()\n",
        "movie_convers[:3]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\\n\",\n",
              " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\\n\",\n",
              " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXiwE91L_UH8",
        "outputId": "9285fb01-ce4d-4a5c-d172-751c8d185e0f"
      },
      "source": [
        "with codecs.open('./drive/My Drive/ChatBot_Dataset/movie_lines.txt', encoding='cp1251', errors='ignore') as file:\n",
        "    movie_lines = [movie_lines for movie_lines in file]\n",
        "\n",
        "movie_lines[:3]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n',\n",
              " 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n',\n",
              " 'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "o-eArYa1_euj",
        "outputId": "b3b90c8c-cb31-48f5-99df-ba4ac9d48c82"
      },
      "source": [
        "# Предварительная обработка данных\n",
        "# преобразование данных нашего списка в датафрейм (movie_convers)\n",
        "id1 = []\n",
        "id2 = []\n",
        "movie_id = []\n",
        "dialogues = []\n",
        "\n",
        "for line in movie_convers:\n",
        "  line_row = line.split('+++$+++')\n",
        "  id1.append(line_row[0].strip())\n",
        "  id2.append(line_row[1].strip())\n",
        "  movie_id.append(line_row[2].strip())\n",
        "  dialogues.append(line_row[3].strip())\n",
        "\n",
        "movie_convers_df = pd.DataFrame({'id1': id1, \n",
        "                                 'id2': id2, \n",
        "                                 'movie_id': movie_id, \n",
        "                                 'dialogues': dialogues}, \n",
        "                                columns = ['id1', \n",
        "                                           'id2', \n",
        "                                           'movie_id', \n",
        "                                           'dialogues'])\n",
        "print(movie_convers_df.shape)\n",
        "movie_convers_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(83097, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id1</th>\n",
              "      <th>id2</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>dialogues</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L194', 'L195', 'L196', 'L197']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L198', 'L199']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L200', 'L201', 'L202', 'L203']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L204', 'L205', 'L206']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>u0</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>['L207', 'L208']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  id1 id2 movie_id                         dialogues\n",
              "0  u0  u2       m0  ['L194', 'L195', 'L196', 'L197']\n",
              "1  u0  u2       m0                  ['L198', 'L199']\n",
              "2  u0  u2       m0  ['L200', 'L201', 'L202', 'L203']\n",
              "3  u0  u2       m0          ['L204', 'L205', 'L206']\n",
              "4  u0  u2       m0                  ['L207', 'L208']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "Wwe-737OBqYq",
        "outputId": "f28a99f9-acc7-4d69-bc59-d4ed2c45716c"
      },
      "source": [
        "# преобразование данных нашего списка в датафрейм (movie_lines)\n",
        "\n",
        "line_id = []\n",
        "character_id = []\n",
        "movie_id = []\n",
        "name = []\n",
        "text = []\n",
        "\n",
        "for line in movie_lines: \n",
        "    line = line.replace('\\t', '')\n",
        "    line = line.replace('\\xad', '')\n",
        "    line_row = line.split('+++$+++')\n",
        "    line_id.append(line_row[0].strip())\n",
        "    character_id.append(line_row[1].strip())\n",
        "    movie_id.append(line_row[2].strip())\n",
        "    name.append(line_row[3].strip())\n",
        "    text.append(line_row[4].strip())\n",
        "\n",
        "movie_lines_df = pd.DataFrame({'line_id': line_id, \n",
        "                               'character_id': character_id, \n",
        "                               'movie_id': movie_id, \n",
        "                               'name': name, \n",
        "                               'text': text}, \n",
        "                                columns = ['line_id', \n",
        "                                           'character_id', \n",
        "                                           'movie_id', \n",
        "                                           'name', \n",
        "                                           'text']) \n",
        "\n",
        "print(movie_lines_df.shape)\n",
        "movie_lines_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(304713, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>line_id</th>\n",
              "      <th>character_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L1045</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>They do not!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L1044</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td>They do to!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>L985</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>I hope so.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>L984</td>\n",
              "      <td>u2</td>\n",
              "      <td>m0</td>\n",
              "      <td>CAMERON</td>\n",
              "      <td>She okay?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>L925</td>\n",
              "      <td>u0</td>\n",
              "      <td>m0</td>\n",
              "      <td>BIANCA</td>\n",
              "      <td>Let's go.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  line_id character_id movie_id     name          text\n",
              "0   L1045           u0       m0   BIANCA  They do not!\n",
              "1   L1044           u2       m0  CAMERON   They do to!\n",
              "2    L985           u0       m0   BIANCA    I hope so.\n",
              "3    L984           u2       m0  CAMERON     She okay?\n",
              "4    L925           u0       m0   BIANCA     Let's go."
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCL06AlzCAat"
      },
      "source": [
        "movie_array = movie_lines_df.iloc[:, 4:5].to_numpy()[:10000]\n",
        "input_texts = movie_array[:-1]\n",
        "target_texts = movie_array[1:]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wl0Hj7JCa8y"
      },
      "source": [
        "# Преобразуем данные в словарь\n",
        "def prepare_vocab(texts):\n",
        "    vocab = sorted(set(' '.join(map(str, texts))))\n",
        "    vocab.append('<START>')\n",
        "    vocab.append('<END>')\n",
        "    vocab_size = len(vocab)\n",
        "    char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "    idx2char = np.array(vocab)\n",
        "    return vocab_size, char2idx, idx2char\n",
        "\n",
        "INPUT_VOCAB_SIZE, input_char2idx, input_idx2char = prepare_vocab(input_texts)\n",
        "TARGET_VOCAB_SIZE, target_char2idx, target_idx2char = prepare_vocab(target_texts)\n",
        "\n",
        "# преобразуем массивы списков в массивы строк\n",
        "input_texts = np.resize(input_texts, (input_texts.shape[0], ))\n",
        "target_texts = np.resize(target_texts, (target_texts.shape[0], ))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk4HC8RoDYE4"
      },
      "source": [
        "# encoder&decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXhD1DusC30r"
      },
      "source": [
        "# encoder&decoder\n",
        "input_texts_as_int = [[input_char2idx[c] for c in text] for text in input_texts]\n",
        "target_texts_as_int = [[target_char2idx[c] for c in text] for text in target_texts]\n",
        "\n",
        "encoder_input_seqs = [np.array(text) for text in input_texts_as_int]\n",
        "decoder_input_seqs = []\n",
        "decoder_target_seqs = []\n",
        "for target_text in target_texts_as_int:\n",
        "    decoder_input_seqs.append(np.array([target_char2idx['<START>']] + target_text))\n",
        "    decoder_target_seqs.append(np.array(target_text + [target_char2idx['<END>']]))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D3tP2SEDc_f",
        "outputId": "956112d9-8b0b-424a-f0ba-e9cb2a2aa142"
      },
      "source": [
        "print(encoder_input_seqs[:3])\n",
        "print('-----------------')\n",
        "print(decoder_input_seqs[:3])\n",
        "print('-----------------')\n",
        "print(decoder_target_seqs[:3])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([47, 65, 62, 82,  0, 61, 72,  0, 71, 72, 77,  1]), array([47, 65, 62, 82,  0, 61, 72,  0, 77, 72,  1]), array([36,  0, 65, 72, 73, 62,  0, 76, 72, 11])]\n",
            "-----------------\n",
            "[array([87, 47, 65, 62, 82,  0, 61, 72,  0, 77, 72,  1]), array([87, 36,  0, 65, 72, 73, 62,  0, 76, 72, 11]), array([87, 46, 65, 62,  0, 72, 68, 58, 82, 27])]\n",
            "-----------------\n",
            "[array([47, 65, 62, 82,  0, 61, 72,  0, 77, 72,  1, 88]), array([36,  0, 65, 72, 73, 62,  0, 76, 72, 11, 88]), array([46, 65, 62,  0, 72, 68, 58, 82, 27, 88])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yksu9QtSC38O"
      },
      "source": [
        "max_enc_seq_length = max([len(seq) for seq in encoder_input_seqs])\n",
        "max_dec_seq_length = max([len(seq) for seq in decoder_input_seqs])\n",
        "\n",
        "encoder_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    encoder_input_seqs,\n",
        "    value=input_char2idx[' '],\n",
        "    padding='post',\n",
        "    maxlen=max_enc_seq_length)\n",
        "\n",
        "decoder_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    decoder_input_seqs,\n",
        "    value=target_char2idx[' '],\n",
        "    padding='post',\n",
        "    maxlen=max_dec_seq_length)\n",
        "\n",
        "decoder_target_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    decoder_target_seqs,\n",
        "    value=target_char2idx[' '],\n",
        "    padding='post',\n",
        "    maxlen=max_dec_seq_length)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFwBzFKvEBLo"
      },
      "source": [
        "# Создание модели\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpJauy2PDywm"
      },
      "source": [
        "H_SIZE = 256 # Размерность скрытого состояния LSTM\n",
        "EMB_SIZE = 256 # размерность эмбеддингов (и для входных и для выходных цепочек)\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em56NODmVfTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e488cba9-686e-46f7-9703-a9bd437f3cce"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(INPUT_VOCAB_SIZE, EMB_SIZE)\n",
        "        self.lstm0 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(H_SIZE, \n",
        "                                                                        return_sequences=True, \n",
        "                                                                        return_state=True)) \n",
        "        self.lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(H_SIZE, \n",
        "                                                                        return_sequences=False, \n",
        "                                                                        return_state=True))\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embed(x)\n",
        "        out, h0_f, c0_f, h0_b, c0_b = self.lstm0(out)\n",
        "        out, h1_f, c1_f, h1_b, c1_b = self.lstm1(out)\n",
        "        h0 = tf.keras.layers.Concatenate()([h0_f, h0_b])\n",
        "        c0 = tf.keras.layers.Concatenate()([c0_f, c0_b])\n",
        "        h1 = tf.keras.layers.Concatenate()([h1_f, h1_b])\n",
        "        c1 = tf.keras.layers.Concatenate()([c1_f, c1_b])\n",
        "        state = [(h0, c0), (h1, c1)]\n",
        "        return state\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(TARGET_VOCAB_SIZE, EMB_SIZE)\n",
        "        self.lstm0 = tf.keras.layers.LSTM(H_SIZE*2, \n",
        "                                          return_sequences=True, \n",
        "                                          return_state=True)\n",
        "        self.lstm1 = tf.keras.layers.LSTM(H_SIZE*2, \n",
        "                                          return_sequences=True, \n",
        "                                          return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(TARGET_VOCAB_SIZE, activation='softmax')\n",
        "\n",
        "    def call(self, x, init_state):\n",
        "        out = self.embed(x)\n",
        "        out, h0, c0 = self.lstm0(out, initial_state=init_state[0])\n",
        "        out, h1, c1 = self.lstm1(out, initial_state=init_state[1])\n",
        "\n",
        "        out = self.fc(out)\n",
        "        state = [(h0, c0), (h1, c1)]\n",
        "        return out, state\n",
        "\n",
        "encoder_model = Encoder()\n",
        "decoder_model = Decoder()\n",
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "enc_state = encoder_model(encoder_inputs)\n",
        "decoder_outputs, _ = decoder_model(decoder_inputs, enc_state)\n",
        "\n",
        "seq2seq = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "seq2seq.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Encoder)               [((None, 512), (None 2648320     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Decoder)               ((None, None, 89), [ 3742553     input_2[0][0]                    \n",
            "                                                                 encoder[0][0]                    \n",
            "                                                                 encoder[0][1]                    \n",
            "                                                                 encoder[0][2]                    \n",
            "                                                                 encoder[0][3]                    \n",
            "==================================================================================================\n",
            "Total params: 6,390,873\n",
            "Trainable params: 6,390,873\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDcTqdtmGhNj",
        "outputId": "f65c3986-cbd2-477e-deea-3a13e155e288"
      },
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "loss = tf.losses.SparseCategoricalCrossentropy()\n",
        "seq2seq.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
        "seq2seq.fit([encoder_input_seqs, decoder_input_seqs], decoder_target_seqs, \n",
        "            batch_size=BATCH_SIZE, \n",
        "            epochs=EPOCHS)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 528s 3s/step - loss: 0.2183 - accuracy: 0.9600\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 513s 3s/step - loss: 0.1461 - accuracy: 0.9655\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 510s 3s/step - loss: 0.1291 - accuracy: 0.9667\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 510s 3s/step - loss: 0.1211 - accuracy: 0.9678\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 510s 3s/step - loss: 0.1139 - accuracy: 0.9691\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 510s 3s/step - loss: 0.1052 - accuracy: 0.9711\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 510s 3s/step - loss: 0.0994 - accuracy: 0.9718\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 511s 3s/step - loss: 0.0958 - accuracy: 0.9727\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 511s 3s/step - loss: 0.0928 - accuracy: 0.9737\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 511s 3s/step - loss: 0.0900 - accuracy: 0.9744\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9028e7ee50>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eIgCTDPWjcW"
      },
      "source": [
        "# Функция для инференса\n",
        "\n",
        "def seq2seq_inference(input_seq):\n",
        "    state = encoder_model(input_seq)\n",
        "\n",
        "    target_seq = np.array([[target_char2idx['<START>']]])\n",
        "\n",
        "    decoded_sentence = ''\n",
        "    while True:\n",
        "        output_tokens, state = decoder_model(target_seq, state)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = target_idx2char[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '<END>' or\n",
        "           len(decoded_sentence) > max_dec_seq_length):\n",
        "            break\n",
        "\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCthRGlHeEN3",
        "outputId": "ef85bfef-ecfb-40ff-86da-d1a95387a750"
      },
      "source": [
        "# Пример инференса\n",
        "for seq_index in range(70, 80):\n",
        "    input_seq = encoder_input_seqs[seq_index: seq_index + 1]\n",
        "    decoded_sentence = seq2seq_inference(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Result sentence:', decoded_sentence)\n",
        "    print('Target sentence:', target_texts[seq_index])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: You think you ' re the only sophomore at the prom?\n",
            "Result sentence: I don't the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "Target sentence: I don't have to be home 'til two.\n",
            "-\n",
            "Input sentence: I don't have to be home 'til two.\n",
            "Result sentence: I don't the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "Target sentence: I have to be home in twenty minutes.\n",
            "-\n",
            "Input sentence: I have to be home in twenty minutes.\n",
            "Result sentence: I don't the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "Target sentence: All I know is -- I'd give up my private line to go out with a guy like Joey.\n",
            "-\n",
            "Input sentence: All I know is -- I'd give up my private line to go out with a guy like Joey.\n",
            "Result sentence: I don't the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "Target sentence: Sometimes I wonder if the guys we're supposed to want to go out with are the ones we actually want to go out with, you know?\n",
            "-\n",
            "Input sentence: Sometimes I wonder if the guys we're supposed to want to go out with are the ones we actually want to go out with, you know?\n",
            "Result sentence: I don't the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "Target sentence: Bianca, I don't think the highlights of dating Joey Dorsey are going to include door-opening and coat-holding.\n",
            "-\n",
            "Input sentence: Bianca, I don't think the highlights of dating Joey Dorsey are going to include door-opening and coat-holding.\n",
            "Result sentence: I don't the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "Target sentence: Combination.  I don't know -- I thought he'd be different.  More of a gentleman...\n",
            "-\n",
            "Input sentence: Combination.  I don't know -- I thought he'd be different.  More of a gentleman...\n",
            "Result sentence: I don't the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "Target sentence: Is he oily or dry?\n",
            "-\n",
            "Input sentence: Is he oily or dry?\n",
            "Result sentence: I don't the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "Target sentence: He practically proposed when he found out we had the same dermatologist. I mean. Dr. Bonchowski is great an all, but he's not exactly relevant party conversation.\n",
            "-\n",
            "Input sentence: He practically proposed when he found out we had the same dermatologist. I mean. Dr. Bonchowski is great an all, but he's not exactly relevant party conversation.\n",
            "Result sentence: I don't the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "Target sentence: Would you mind getting me a drink, Cameron?\n",
            "-\n",
            "Input sentence: Would you mind getting me a drink, Cameron?\n",
            "Result sentence: I don't the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "Target sentence: Great\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V85kp76eVL1"
      },
      "source": [
        "# Encoder&Decoder with attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWogqr9BeMNM",
        "outputId": "c6bbde8c-3ac3-418a-bb54-b5b3da8fa2fa"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(INPUT_VOCAB_SIZE, EMB_SIZE)\n",
        "        self.lstm0 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(H_SIZE, \n",
        "                                                                        return_sequences=True, \n",
        "                                                                        return_state=True)) \n",
        "        self.lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(H_SIZE, \n",
        "                                                                        return_sequences=True, \n",
        "                                                                        return_state=True))\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embed(x)\n",
        "        out, h0_f, c0_f, h0_b, c0_b = self.lstm0(out)\n",
        "        out, h1_f, c1_f, h1_b, c1_b = self.lstm1(out)\n",
        "        h0 = tf.keras.layers.Concatenate()([h0_f, h0_b])\n",
        "        c0 = tf.keras.layers.Concatenate()([c0_f, c0_b])\n",
        "        h1 = tf.keras.layers.Concatenate()([h1_f, h1_b])\n",
        "        c1 = tf.keras.layers.Concatenate()([c1_f, c1_b])\n",
        "        state = [(h0, c0), (h1, c1)]\n",
        "        return out, state\n",
        "\n",
        "class Attention(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.dense1 = tf.keras.layers.Dense(1, \n",
        "                                          input_shape=(1, \n",
        "                                                       encoder_input_seqs.shape[1], \n",
        "                                                       H_SIZE*2), activation=\"softmax\")\n",
        "\n",
        "    def call(self, encoder_out):\n",
        "      x = encoder_out\n",
        "      x = self.dense1(x)\n",
        "      return x\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(TARGET_VOCAB_SIZE, EMB_SIZE)\n",
        "        self.lstm0 = tf.keras.layers.LSTM(H_SIZE*2, \n",
        "                                          return_sequences=True, \n",
        "                                          return_state=True)\n",
        "        self.lstm1 = tf.keras.layers.LSTM(H_SIZE*2, \n",
        "                                          return_sequences=True, \n",
        "                                          return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(TARGET_VOCAB_SIZE, activation='softmax')\n",
        "         \n",
        "    def call(self, x, init_state, att_out):\n",
        "        out = self.embed(x)\n",
        "        out, h0, c0 = self.lstm0(out, initial_state=init_state[0])\n",
        "        out, h1, c1 = self.lstm1(out, initial_state=init_state[1])\n",
        "        out = tf.concat([out, att_out], 2)\n",
        "        out = self.fc(out)\n",
        "        state = [(h0, c0), (h1, c1)]\n",
        "        return out, state\n",
        "\n",
        "encoder_model = Encoder()\n",
        "decoder_model = Decoder()\n",
        "attention_model = Attention()\n",
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "enc_output, enc_state = encoder_model(encoder_inputs)\n",
        "att_out = attention_model(enc_output)\n",
        "decoder_outputs, _ = decoder_model(decoder_inputs, enc_state, att_out)\n",
        "\n",
        "# общая модель \n",
        "seq2seq = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "seq2seq.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_1 (Encoder)             ((None, None, 512),  2648320     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention (Attention)           (None, None, 1)      513         encoder_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_1 (Decoder)             ((None, None, 89), [ 3742642     input_4[0][0]                    \n",
            "                                                                 encoder_1[0][1]                  \n",
            "                                                                 encoder_1[0][2]                  \n",
            "                                                                 encoder_1[0][3]                  \n",
            "                                                                 encoder_1[0][4]                  \n",
            "                                                                 attention[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 6,391,475\n",
            "Trainable params: 6,391,475\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}